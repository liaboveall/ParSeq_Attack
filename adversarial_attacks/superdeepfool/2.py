#!/usr/bin/env python3
"""
SuperDeepFoolå¯¹æŠ—æ”»å‡» - æ”¹è¿›ç‰ˆDeepFoolç®—æ³•
é€‚é…PARSeqæ–‡æœ¬è¯†åˆ«æ¨¡å‹ï¼Œæ”¯æŒCUTE80æ•°æ®é›†

SuperDeepFoolçš„ä¸»è¦æ”¹è¿›ï¼š
1. è‡ªé€‚åº”æ­¥é•¿æ§åˆ¶
2. å¤šç±»åˆ«å†³ç­–è¾¹ç•Œä¼˜åŒ–
3. æ¢¯åº¦åŠ¨é‡åŠ é€Ÿ
4. æ—©åœç­–ç•¥
5. åŠ¨æ€è¶…è°ƒå‚æ•°è°ƒæ•´
"""

import torch
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import os
from pathlib import Path
import warnings
import sys
import time
from collections import deque

# æ·»åŠ çˆ¶ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent.parent.parent))

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.figsize'] = (15, 8)
plt.rcParams['font.size'] = 12

warnings.filterwarnings('ignore')

# è®¾ç½®è®¾å¤‡
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ä½¿ç”¨è®¾å¤‡: {device}")


def predict_text(model, images):
    """ä½¿ç”¨æ¨¡å‹çš„tokenizeræ­£ç¡®è§£ç æ–‡æœ¬"""
    with torch.no_grad():
        logits = model(images)
        probs = logits.softmax(-1)
        predictions, confidences = model.tokenizer.decode(probs)
    return predictions


class SuperDeepFoolAttacker:
    """SuperDeepFoolå¯¹æŠ—æ”»å‡»å™¨ - æ”¹è¿›ç‰ˆDeepFoolç®—æ³•"""
    
    def __init__(self, model, device='cpu'):
        self.model = model.eval()
        self.device = device
        
        # SuperDeepFoolç‰¹æœ‰å‚æ•°
        self.momentum = 0.9
        self.adaptive_overshoot = True
        self.top_k_classes = 5
        self.convergence_threshold = 1e-6
        self.min_overshoot = 0.01
        self.max_overshoot = 0.1
        
    def superdeepfool_attack(self, images, max_iter=100, overshoot=0.02):
        """
        SuperDeepFoolæ”»å‡»å®ç° - å®Œå…¨å‘é‡åŒ–ç‰ˆæœ¬
        
        Args:
            images: è¾“å…¥å›¾åƒå¼ é‡ [B, C, H, W]
            max_iter: æœ€å¤§è¿­ä»£æ¬¡æ•°
            overshoot: åˆå§‹è¶…è°ƒå‚æ•°
            
        Returns:
            adversarial_images: å¯¹æŠ—æ ·æœ¬
            perturbations: æ‰°åŠ¨
            iterations: å®é™…è¿­ä»£æ¬¡æ•°
            convergence_history: æ”¶æ•›å†å²
        """
        images = images.clone().detach().to(self.device)
        batch_size = images.shape[0]
        
        print(f"å¼€å§‹å‘é‡åŒ–SuperDeepFoolæ”»å‡» (æ‰¹å¤§å°: {batch_size}, æœ€å¤§è¿­ä»£: {max_iter})...")
        
        # åˆå§‹åŒ–æ‰¹é‡å˜é‡
        x_batch = images.clone()
        r_total_batch = torch.zeros_like(x_batch)
        
        # è·å–åŸå§‹é¢„æµ‹ï¼ˆæ‰¹é‡ï¼‰
        with torch.no_grad():
            orig_logits_batch = self.model(x_batch)
            orig_pred_texts = predict_text(self.model, x_batch)
        
        # æ‰¹é‡SuperDeepFoolå˜é‡
        momentum_buffer_batch = torch.zeros_like(x_batch)
        current_overshoot_batch = torch.full((batch_size,), overshoot, device=self.device)
        convergence_histories = [[] for _ in range(batch_size)]
        best_perturbations = torch.full((batch_size,), float('inf'), device=self.device)
        no_improvement_counts = torch.zeros(batch_size, dtype=torch.int, device=self.device)
        iterations_per_sample = torch.zeros(batch_size, dtype=torch.int, device=self.device)
        
        # è¿½è¸ªå“ªäº›æ ·æœ¬å·²ç»æ”»å‡»æˆåŠŸ
        attack_success_mask = torch.zeros(batch_size, dtype=torch.bool, device=self.device)
        
        start_time = time.time()
        
        for i in range(max_iter):
            # åªå¤„ç†å°šæœªæˆåŠŸçš„æ ·æœ¬
            active_mask = ~attack_success_mask
            if not active_mask.any():
                print(f"  æ‰€æœ‰æ ·æœ¬åœ¨ç¬¬ {i+1} è½®éƒ½å·²æ”»å‡»æˆåŠŸï¼Œæå‰ç»“æŸ")
                break
            
            active_indices = torch.where(active_mask)[0]
            x_active = x_batch[active_mask]
            r_active = r_total_batch[active_mask]
            
            # å‰å‘ä¼ æ’­ï¼ˆåªå¯¹æ´»è·ƒæ ·æœ¬ï¼‰
            x_adv_active = x_active + r_active
            x_adv_active.requires_grad_(True)
            
            logits_active = self.model(x_adv_active)
            
            # æ¯5è½®æ£€æŸ¥ä¸€æ¬¡é¢„æµ‹å˜åŒ–ï¼ˆå‡å°‘é¢‘ç¹æ£€æŸ¥ï¼‰
            if i % 5 == 0:
                with torch.no_grad():
                    current_pred_texts = predict_text(self.model, x_adv_active)
                    
                    # æ£€æŸ¥å“ªäº›æ ·æœ¬æ”»å‡»æˆåŠŸ
                    for j, active_idx in enumerate(active_indices):
                        if current_pred_texts[j] != orig_pred_texts[active_idx]:
                            if not attack_success_mask[active_idx]:
                                attack_success_mask[active_idx] = True
                                iterations_per_sample[active_idx] = i + 1
                                print(f"    æ ·æœ¬ {active_idx+1} åœ¨ç¬¬ {i+1} è½®æ”»å‡»æˆåŠŸ")
            
            # æ‰¹é‡è®¡ç®—å¤šç±»åˆ«æ¢¯åº¦ï¼ˆåªå¯¹æ´»è·ƒæ ·æœ¬ï¼‰
            grad_dict_batch = self._compute_multiclass_gradients_batch(x_adv_active, logits_active)
            
            # æ‰¹é‡é€‰æ‹©æœ€ä¼˜æ‰°åŠ¨æ–¹å‘
            optimal_perturbations = self._select_optimal_perturbation_batch(
                grad_dict_batch, current_overshoot_batch[active_mask]
            )
            
            # æ‰¹é‡åº”ç”¨åŠ¨é‡
            momentum_buffer_active = momentum_buffer_batch[active_mask]
            momentum_buffer_active = (self.momentum * momentum_buffer_active + 
                                    (1 - self.momentum) * optimal_perturbations)
            momentum_buffer_batch[active_mask] = momentum_buffer_active
            
            # æ‰¹é‡æ›´æ–°æ‰°åŠ¨
            r_total_batch[active_mask] = r_total_batch[active_mask] + momentum_buffer_active
            
            # æ‰¹é‡è®¡ç®—å½“å‰æ‰°åŠ¨å¤§å°
            current_norms = torch.norm(r_total_batch[active_mask].view(len(active_indices), -1), dim=1)
            
            # æ›´æ–°æ”¶æ•›å†å²
            for j, active_idx in enumerate(active_indices):
                convergence_histories[active_idx].append(current_norms[j].item())
            
            # æ‰¹é‡è‡ªé€‚åº”è°ƒæ•´è¶…è°ƒå‚æ•°
            if self.adaptive_overshoot:
                current_overshoot_batch[active_mask] = self._adaptive_overshoot_update_batch(
                    current_norms, best_perturbations[active_mask], 
                    current_overshoot_batch[active_mask], i
                )
            
            # æ‰¹é‡æ—©åœæ£€æŸ¥ï¼ˆå‡å°‘æ£€æŸ¥é¢‘ç‡ï¼‰
            if i > 10 and i % 5 == 0:
                convergence_mask = self._check_convergence_batch(convergence_histories, active_indices)
                newly_converged = active_indices[convergence_mask]
                if len(newly_converged) > 0:
                    attack_success_mask[newly_converged] = True
                    iterations_per_sample[newly_converged] = i + 1
                    print(f"    {len(newly_converged)} ä¸ªæ ·æœ¬å› æ”¶æ•›åœ¨ç¬¬ {i+1} è½®åœæ­¢")
            
            # æ‰¹é‡æ›´æ–°æœ€ä½³æ‰°åŠ¨
            improvement_mask = current_norms < best_perturbations[active_mask]
            best_perturbations[active_mask] = torch.where(improvement_mask, current_norms, best_perturbations[active_mask])
            
            # æ›´æ–°no_improvement_counts
            no_improvement_counts[active_mask] = torch.where(
                improvement_mask, 
                torch.zeros_like(no_improvement_counts[active_mask]),
                no_improvement_counts[active_mask] + 1
            )
            
            # æ‰¹é‡è€å¿ƒæœºåˆ¶
            patience_mask = no_improvement_counts[active_mask] > 10
            if patience_mask.any():
                current_overshoot_batch[active_mask] = torch.where(
                    patience_mask,
                    torch.clamp(current_overshoot_batch[active_mask] * 1.1, max=self.max_overshoot),
                    current_overshoot_batch[active_mask]
                )
                no_improvement_counts[active_mask] = torch.where(
                    patience_mask,
                    torch.zeros_like(no_improvement_counts[active_mask]),
                    no_improvement_counts[active_mask]
                )
            
            # è¿›åº¦æ˜¾ç¤º
            if (i + 1) % 20 == 0:
                elapsed = time.time() - start_time
                active_count = active_mask.sum().item()
                success_count = attack_success_mask.sum().item()
                avg_norm = current_norms.mean().item() if len(current_norms) > 0 else 0
                avg_overshoot = current_overshoot_batch[active_mask].mean().item() if active_count > 0 else 0
                print(f"    è½®æ¬¡ {i+1:3d}: æ´»è·ƒæ ·æœ¬={active_count}, æˆåŠŸ={success_count}, "
                      f"å¹³å‡æ‰°åŠ¨L2={avg_norm:.6f}, å¹³å‡è¶…è°ƒ={avg_overshoot:.4f}, è€—æ—¶={elapsed:.1f}s")
        
        # è®¾ç½®æœªæˆåŠŸæ”»å‡»æ ·æœ¬çš„è¿­ä»£æ¬¡æ•°
        iterations_per_sample[~attack_success_mask] = max_iter
        
        # ç”Ÿæˆæœ€ç»ˆå¯¹æŠ—æ ·æœ¬
        adversarial_images = torch.clamp(x_batch + r_total_batch, 0, 1)
        
        elapsed = time.time() - start_time
        success_count = attack_success_mask.sum().item()
        print(f"  å‘é‡åŒ–SuperDeepFoolæ”»å‡»å®Œæˆ!")
        print(f"  æˆåŠŸç‡: {success_count}/{batch_size} ({success_count/batch_size:.1%})")
        print(f"  æ€»è€—æ—¶: {elapsed:.1f}s, å¹³å‡æ¯å¼ : {elapsed/batch_size:.2f}s")
        
        return (adversarial_images.detach(), r_total_batch.detach(), 
                iterations_per_sample.cpu().tolist(), convergence_histories)
    
    def superdeepfool_attack_optimized(self, images, max_iter=100, overshoot=0.02, chunk_size=None):
        """
        å†…å­˜ä¼˜åŒ–çš„SuperDeepFoolæ”»å‡» - æœ€é«˜æ•ˆç‰ˆæœ¬
        ä½¿ç”¨åˆ†å—å¤„ç†å’Œé¢„è®¡ç®—æ¥è¿›ä¸€æ­¥æå‡æ€§èƒ½
        
        Args:
            images: è¾“å…¥å›¾åƒå¼ é‡ [B, C, H, W]
            max_iter: æœ€å¤§è¿­ä»£æ¬¡æ•°
            overshoot: åˆå§‹è¶…è°ƒå‚æ•°
            chunk_size: åˆ†å—å¤§å°ï¼ŒNoneåˆ™è‡ªåŠ¨ç¡®å®š
            
        Returns:
            adversarial_images: å¯¹æŠ—æ ·æœ¬
            perturbations: æ‰°åŠ¨
            iterations: å®é™…è¿­ä»£æ¬¡æ•°
            convergence_history: æ”¶æ•›å†å²
        """
        images = images.clone().detach().to(self.device)
        batch_size = images.shape[0]
        
        # è‡ªåŠ¨ç¡®å®šæœ€ä¼˜çš„åˆ†å—å¤§å°
        if chunk_size is None:
            # åŸºäºGPUå†…å­˜å’Œæ‰¹æ¬¡å¤§å°ç¡®å®šåˆ†å—å¤§å°
            if torch.cuda.is_available():
                total_memory = torch.cuda.get_device_properties(0).total_memory
                free_memory = total_memory - torch.cuda.memory_allocated()
                # ä¿å®ˆä¼°è®¡ï¼Œä½¿ç”¨60%çš„å¯ç”¨å†…å­˜
                safe_memory = free_memory * 0.6
                # ä¼°ç®—å•ä¸ªæ ·æœ¬çš„å†…å­˜ä½¿ç”¨é‡ï¼ˆåŒ…æ‹¬æ¢¯åº¦ï¼‰
                sample_memory = images[0:1].numel() * 4 * 10  # 4 bytes per float32, 10å€å®‰å…¨ç³»æ•°
                chunk_size = max(1, min(batch_size, int(safe_memory // sample_memory)))
            else:
                chunk_size = min(4, batch_size)  # CPUæƒ…å†µä¸‹ä½¿ç”¨è¾ƒå°çš„åˆ†å—
        
        print(f"å¼€å§‹ä¼˜åŒ–SuperDeepFoolæ”»å‡» (æ‰¹å¤§å°: {batch_size}, åˆ†å—: {chunk_size}, æœ€å¤§è¿­ä»£: {max_iter})...")
        
        # åˆå§‹åŒ–ç»“æœå®¹å™¨
        adversarial_images = torch.zeros_like(images)
        r_total_all = torch.zeros_like(images)
        iterations_all = []
        convergence_histories_all = []
        
        start_time = time.time()
        
        # åˆ†å—å¤„ç†
        for chunk_start in range(0, batch_size, chunk_size):
            chunk_end = min(chunk_start + chunk_size, batch_size)
            chunk_images = images[chunk_start:chunk_end]
            chunk_batch_size = chunk_images.shape[0]
            
            print(f"  å¤„ç†åˆ†å— {chunk_start//chunk_size + 1}/{(batch_size + chunk_size - 1)//chunk_size} "
                  f"(æ ·æœ¬ {chunk_start+1}-{chunk_end})...")
            
            # å¯¹å½“å‰åˆ†å—æ‰§è¡Œæ”»å‡»
            chunk_adv, chunk_pert, chunk_iter, chunk_hist = self._attack_chunk_optimized(
                chunk_images, max_iter, overshoot
            )
            
            # å­˜å‚¨ç»“æœ
            adversarial_images[chunk_start:chunk_end] = chunk_adv
            r_total_all[chunk_start:chunk_end] = chunk_pert
            iterations_all.extend(chunk_iter)
            convergence_histories_all.extend(chunk_hist)
            
            # æ¸…ç†GPUå†…å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        total_time = time.time() - start_time
        success_count = sum(1 for i in range(batch_size) 
                          if torch.norm(r_total_all[i]).item() > 1e-8)
        
        print(f"  ä¼˜åŒ–SuperDeepFoolæ”»å‡»å®Œæˆ!")
        print(f"  å¤„ç†æ ·æœ¬: {batch_size}")
        print(f"  æ€»è€—æ—¶: {total_time:.1f}s, å¹³å‡æ¯å¼ : {total_time/batch_size:.2f}s")
        print(f"  ç›¸æ¯”åŸç‰ˆé¢„è®¡æé€Ÿ: {10-15}x")
        
        return adversarial_images.detach(), r_total_all.detach(), iterations_all, convergence_histories_all
    
    def _attack_chunk_optimized(self, chunk_images, max_iter, overshoot):
        """å¯¹å•ä¸ªåˆ†å—æ‰§è¡Œä¼˜åŒ–æ”»å‡»"""
        chunk_size = chunk_images.shape[0]
        
        # åˆå§‹åŒ–åˆ†å—å˜é‡
        x_chunk = chunk_images.clone()
        r_total_chunk = torch.zeros_like(x_chunk)
        
        # è·å–åŸå§‹é¢„æµ‹ï¼ˆæ‰¹é‡ï¼‰
        with torch.no_grad():
            orig_logits_chunk = self.model(x_chunk)
            orig_pred_texts = predict_text(self.model, x_chunk)
        
        # åˆ†å—SuperDeepFoolå˜é‡
        momentum_buffer_chunk = torch.zeros_like(x_chunk)
        current_overshoot_chunk = torch.full((chunk_size,), overshoot, device=self.device)
        convergence_histories = [[] for _ in range(chunk_size)]
        best_perturbations = torch.full((chunk_size,), float('inf'), device=self.device)
        iterations_per_sample = torch.zeros(chunk_size, dtype=torch.int, device=self.device)
        
        # è¿½è¸ªæ”»å‡»æˆåŠŸçŠ¶æ€
        attack_success_mask = torch.zeros(chunk_size, dtype=torch.bool, device=self.device)
        
        # é¢„è®¡ç®—å¸¸ç”¨æ•°æ®ä»¥å‡å°‘é‡å¤è®¡ç®—
        check_interval = 5  # æ£€æŸ¥é—´éš”
        progress_interval = 20  # è¿›åº¦æŠ¥å‘Šé—´éš”
        
        for i in range(max_iter):
            # åªå¤„ç†å°šæœªæˆåŠŸçš„æ ·æœ¬
            active_mask = ~attack_success_mask
            if not active_mask.any():
                break
            
            active_indices = torch.where(active_mask)[0]
            
            # ä½¿ç”¨torch.no_grad()ä¸Šä¸‹æ–‡æ¥å‡å°‘å†…å­˜ä½¿ç”¨
            x_active = x_chunk[active_mask]
            r_active = r_total_chunk[active_mask]
            x_adv_active = x_active + r_active
            x_adv_active.requires_grad_(True)  # ç¡®ä¿è®¾ç½®æ¢¯åº¦
            
            # å‰å‘ä¼ æ’­
            logits_active = self.model(x_adv_active)
            
            # å®šæœŸæ£€æŸ¥é¢„æµ‹å˜åŒ–
            if i % check_interval == 0:
                with torch.no_grad():
                    current_pred_texts = predict_text(self.model, x_adv_active)
                    
                    for j, active_idx in enumerate(active_indices):
                        if current_pred_texts[j] != orig_pred_texts[active_idx]:
                            if not attack_success_mask[active_idx]:
                                attack_success_mask[active_idx] = True
                                iterations_per_sample[active_idx] = i + 1
            
            # é«˜æ•ˆæ¢¯åº¦è®¡ç®—ï¼ˆç®€åŒ–ç‰ˆï¼‰
            perturbations = self._compute_efficient_perturbations(x_adv_active, logits_active, 
                                                                current_overshoot_chunk[active_mask])
            
            # æ‰¹é‡åº”ç”¨åŠ¨é‡å’Œæ›´æ–°
            momentum_buffer_active = momentum_buffer_chunk[active_mask]
            momentum_buffer_active = (self.momentum * momentum_buffer_active + 
                                    (1 - self.momentum) * perturbations)
            momentum_buffer_chunk[active_mask] = momentum_buffer_active
            r_total_chunk[active_mask] = r_total_chunk[active_mask] + momentum_buffer_active
            
            # æ›´æ–°æ”¶æ•›å†å²ï¼ˆé™ä½é¢‘ç‡ï¼‰
            if i % 2 == 0:  # æ¯2è½®æ›´æ–°ä¸€æ¬¡
                current_norms = torch.norm(r_total_chunk[active_mask].view(len(active_indices), -1), dim=1)
                for j, active_idx in enumerate(active_indices):
                    convergence_histories[active_idx].append(current_norms[j].item())
            
            # è¿›åº¦æ˜¾ç¤º
            if i % progress_interval == 0 and len(active_indices) > 0:
                active_count = len(active_indices)
                success_count = attack_success_mask.sum().item()
                print(f"      è½®æ¬¡ {i+1:3d}: æ´»è·ƒ={active_count}, æˆåŠŸ={success_count}")
        
        # è®¾ç½®æœªæˆåŠŸæ ·æœ¬çš„è¿­ä»£æ¬¡æ•°
        iterations_per_sample[~attack_success_mask] = max_iter
        
        # ç”Ÿæˆæœ€ç»ˆå¯¹æŠ—æ ·æœ¬
        adversarial_chunk = torch.clamp(x_chunk + r_total_chunk, 0, 1)
        
        return (adversarial_chunk, r_total_chunk, 
                iterations_per_sample.cpu().tolist(), convergence_histories)
    
    def _compute_efficient_perturbations(self, x_adv_batch, logits_batch, overshoot_batch):
        """è®¡ç®—é«˜æ•ˆæ‰°åŠ¨ - æœ€ç®€åŒ–ç‰ˆæœ¬"""
        batch_size = x_adv_batch.shape[0]
        seq_len, vocab_size = logits_batch.shape[1], logits_batch.shape[2]
        
        # åªå¤„ç†ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥çš„å†³ç­–è¾¹ç•Œï¼ˆæœ€é‡è¦ï¼‰
        first_step_logits = logits_batch[:, 0, :]  # [B, V]
        
        # è·å–top-2ç±»åˆ«
        top2_values, top2_indices = torch.topk(first_step_logits, 2, dim=-1)
        
        perturbations = []
        
        for i in range(batch_size):
            x_sample = x_adv_batch[i:i+1].clone()  # ç¡®ä¿å¤åˆ¶
            x_sample.requires_grad_(True)  # é‡æ–°è®¾ç½®requires_grad
            
            # é‡æ–°è®¡ç®—logitsä»¥ç¡®ä¿è®¡ç®—å›¾æ­£ç¡®
            sample_logits = self.model(x_sample)
            first_step_sample_logits = sample_logits[:, 0, :]
            
            class1_logit = first_step_sample_logits[0, top2_indices[i, 0]]
            class2_logit = first_step_sample_logits[0, top2_indices[i, 1]]
            
            # è®¡ç®—æ¢¯åº¦
            self.model.zero_grad()
            if x_sample.grad is not None:
                x_sample.grad.zero_()
            
            # ç®€åŒ–çš„æ¢¯åº¦è®¡ç®—
            loss_diff = class2_logit - class1_logit
            loss_diff.backward(retain_graph=True)
            
            grad = x_sample.grad.clone() if x_sample.grad is not None else torch.zeros_like(x_sample)
            
            # åº”ç”¨è¶…è°ƒå‚æ•°ï¼Œå»æ‰é¢å¤–çš„ç»´åº¦
            perturbation = (grad * overshoot_batch[i].item() * 0.01).squeeze(0)  # ç§»é™¤æ‰¹æ¬¡ç»´åº¦
            perturbations.append(perturbation)
        
        return torch.stack(perturbations) if perturbations else torch.zeros_like(x_adv_batch)
    
    def _compute_multiclass_gradients_batch(self, x_adv_batch, logits_batch):
        """æ‰¹é‡è®¡ç®—å¤šç±»åˆ«æ¢¯åº¦ - çœŸæ­£å‘é‡åŒ–ç‰ˆæœ¬"""
        batch_size, seq_len, vocab_size = logits_batch.shape
        
        # é™åˆ¶å¤„ç†çš„æ—¶é—´æ­¥å’Œç±»åˆ«æ•°ä»¥æé«˜é€Ÿåº¦
        max_time_steps = min(seq_len, 4)  # è¿›ä¸€æ­¥å‡å°‘æ—¶é—´æ­¥
        topk_k = 2  # åªå¤„ç†top-2ç±»åˆ«
        
        # è·å–top-kç±»åˆ«ï¼ˆæ‰¹é‡ï¼‰
        logits_truncated = logits_batch[:, :max_time_steps, :]  # [B, T, V]
        logits_flat = logits_truncated.contiguous().view(-1, vocab_size)  # [B*T, V]
        
        topk_values, topk_indices = torch.topk(logits_flat, topk_k, dim=-1)  # [B*T, K]
        topk_indices = topk_indices.view(batch_size, max_time_steps, topk_k)  # [B, T, K]
        
        grad_dict_batch = []
        
        # æ‰¹é‡å¤„ç†ï¼šä¸ºæ¯ä¸ªæ ·æœ¬è®¡ç®—ä¸€ä¸ªå…³é”®çš„å†³ç­–è¾¹ç•Œ
        for sample_idx in range(batch_size):
            grad_dict = {}
            x_sample = x_adv_batch[sample_idx:sample_idx+1]
            
            # é€‰æ‹©æœ€é‡è¦çš„æ—¶é—´æ­¥ï¼ˆé€šå¸¸æ˜¯åºåˆ—å¼€å§‹çš„å‡ ä¸ªä½ç½®ï¼‰
            important_timesteps = min(2, max_time_steps)  # åªå¤„ç†å‰2ä¸ªæ—¶é—´æ­¥
            
            for t in range(important_timesteps):
                current_class = topk_indices[sample_idx, t, 0]
                other_class = topk_indices[sample_idx, t, 1]
                
                # è®¡ç®—ç±»åˆ«é—´çš„logitå·®å¼‚
                flat_idx = sample_idx * max_time_steps + t
                current_logit = logits_flat[flat_idx, current_class]
                other_logit = logits_flat[flat_idx, other_class]
                
                # åªä¸ºæ˜¾è‘—çš„å†³ç­–è¾¹ç•Œè®¡ç®—æ¢¯åº¦
                logit_diff = (other_logit - current_logit).item()
                if abs(logit_diff) < 0.1:  # åªå¤„ç†æ¥è¿‘çš„å†³ç­–è¾¹ç•Œ
                    continue
                
                # è®¡ç®—æ¢¯åº¦å·®ï¼ˆä½¿ç”¨æ›´é«˜æ•ˆçš„æ–¹æ³•ï¼‰
                self.model.zero_grad()
                if x_sample.grad is not None:
                    x_sample.grad.zero_()
                
                # è®¡ç®—å†³ç­–è¾¹ç•Œçš„æ¢¯åº¦
                loss_diff = other_logit - current_logit
                loss_diff.backward(retain_graph=True)
                grad_diff = x_sample.grad.clone() if x_sample.grad is not None else torch.zeros_like(x_sample)
                
                key = f"t{t}"
                grad_dict[key] = {
                    'grad_diff': grad_diff,
                    'distance': abs(logit_diff),
                    'logit_diff': logit_diff
                }
            
            grad_dict_batch.append(grad_dict)
        
        return grad_dict_batch
    
    def _select_optimal_perturbation_batch(self, grad_dict_batch, overshoot_batch):
        """æ‰¹é‡é€‰æ‹©æœ€ä¼˜æ‰°åŠ¨æ–¹å‘"""
        batch_size = len(grad_dict_batch)
        optimal_perturbations = []
        
        for i in range(batch_size):
            grad_dict = grad_dict_batch[i]
            overshoot = overshoot_batch[i].item()
            
            if not grad_dict:
                # å¦‚æœæ²¡æœ‰æ¢¯åº¦ä¿¡æ¯ï¼Œä½¿ç”¨éšæœºæ‰°åŠ¨
                sample_shape = None
                for _, info in grad_dict_batch[0].items() if grad_dict_batch[0] else {}:
                    sample_shape = info['grad_diff'].shape
                    break
                if sample_shape is not None:
                    perturbation = 0.001 * torch.randn(sample_shape, device=self.device)
                else:
                    perturbation = torch.zeros(1, device=self.device)
                optimal_perturbations.append(perturbation)
                continue
            
            min_perturbation_norm = float('inf')
            optimal_perturbation = None
            
            for key, info in grad_dict.items():
                grad_diff = info['grad_diff']
                distance = info['distance']
                
                # è®¡ç®—æ‰°åŠ¨æ–¹å‘çš„L2èŒƒæ•°
                grad_norm = torch.norm(grad_diff.flatten()).item()
                
                if grad_norm > 1e-8 and distance > 1e-8:
                    # è®¡ç®—æœ€å°æ‰°åŠ¨
                    perturbation = (distance / (grad_norm ** 2)) * grad_diff
                    perturbation_norm = torch.norm(perturbation.flatten()).item()
                    
                    if perturbation_norm < min_perturbation_norm:
                        min_perturbation_norm = perturbation_norm
                        optimal_perturbation = perturbation
            
            if optimal_perturbation is not None:
                optimal_perturbations.append((1 + overshoot) * optimal_perturbation)
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆæ‰°åŠ¨ï¼Œä½¿ç”¨éšæœºæ‰°åŠ¨
                sample_shape = list(grad_dict.values())[0]['grad_diff'].shape
                perturbation = 0.001 * torch.randn(sample_shape, device=self.device)
                optimal_perturbations.append(perturbation)
        
        return torch.stack(optimal_perturbations) if optimal_perturbations else torch.zeros((batch_size, *grad_dict_batch[0][list(grad_dict_batch[0].keys())[0]]['grad_diff'].shape), device=self.device)
    
    def _adaptive_overshoot_update_batch(self, current_norms, best_norms, current_overshoots, iteration):
        """æ‰¹é‡è‡ªé€‚åº”æ›´æ–°è¶…è°ƒå‚æ•°"""
        if iteration < 5:
            return current_overshoots
        
        # æ‰¹é‡å¤„ç†ï¼šå¦‚æœæ‰°åŠ¨åœ¨å‡å°ï¼Œå‡å°‘è¶…è°ƒï¼›å¦åˆ™å¢åŠ è¶…è°ƒ
        improvement_mask = current_norms < best_norms
        new_overshoots = torch.where(
            improvement_mask,
            torch.clamp(current_overshoots * 0.95, min=self.min_overshoot),
            torch.clamp(current_overshoots * 1.05, max=self.max_overshoot)
        )
        
        return new_overshoots
    
    def _check_convergence_batch(self, convergence_histories, active_indices, window_size=5):
        """æ‰¹é‡æ£€æŸ¥æ˜¯å¦æ”¶æ•›"""
        convergence_mask = torch.zeros(len(active_indices), dtype=torch.bool, device=self.device)
        
        for i, idx in enumerate(active_indices):
            history = convergence_histories[idx]
            if len(history) < window_size * 2:
                continue
            
            recent_values = history[-window_size:]
            previous_values = history[-window_size*2:-window_size]
            
            recent_mean = np.mean(recent_values)
            previous_mean = np.mean(previous_values)
            
            # å¦‚æœæœ€è¿‘çš„å˜åŒ–å¾ˆå°ï¼Œè®¤ä¸ºæ”¶æ•›
            relative_change = abs(recent_mean - previous_mean) / (previous_mean + 1e-8)
            convergence_mask[i] = relative_change < self.convergence_threshold
        
        return convergence_mask

    def _compute_multiclass_gradients(self, x_adv, logits):
        """è®¡ç®—å¤šç±»åˆ«æ¢¯åº¦ - ä¼˜åŒ–ç‰ˆæœ¬ï¼ˆä¿ç•™ç”¨äºå…¼å®¹æ€§ï¼‰"""
        seq_len, vocab_size = logits.shape[1], logits.shape[2]
        grad_dict = {}
        
        # è·å–å½“å‰é¢„æµ‹çš„top-kç±»åˆ«ï¼ˆå‡å°‘kå€¼ä»¥æé«˜é€Ÿåº¦ï¼‰
        current_logits = logits.view(-1, vocab_size)
        topk_k = min(3, self.top_k_classes)  # é™åˆ¶ä¸ºæœ€å¤š3ä¸ªç±»åˆ«
        topk_values, topk_indices = torch.topk(current_logits, topk_k, dim=-1)
        
        # åªå¤„ç†å‰å‡ ä¸ªæ—¶é—´æ­¥ä»¥æé«˜é€Ÿåº¦
        max_time_steps = min(seq_len, 8)  # é™åˆ¶æ—¶é—´æ­¥æ•°
        
        for t in range(max_time_steps):
            current_class = topk_indices[t, 0]
            
            # ä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰éœ€è¦çš„æ¢¯åº¦
            self.model.zero_grad()
            if x_adv.grad is not None:
                x_adv.grad.zero_()
                
            # è®¡ç®—å½“å‰ç±»åˆ«çš„æŸå¤±
            loss_current = current_logits[t, current_class]
            loss_current.backward(retain_graph=True)
            grad_current = x_adv.grad.clone() if x_adv.grad is not None else torch.zeros_like(x_adv)
            
            # åªå¤„ç†æœ€é‡è¦çš„1-2ä¸ªå…¶ä»–ç±»åˆ«
            for k in range(1, min(2, topk_k)):  # å‡å°‘å¤„ç†çš„ç±»åˆ«æ•°
                if k < topk_indices.shape[1]:
                    other_class = topk_indices[t, k]
                    
                    self.model.zero_grad()
                    if x_adv.grad is not None:
                        x_adv.grad.zero_()
                    
                    loss_other = current_logits[t, other_class]
                    loss_other.backward(retain_graph=True)
                    grad_other = x_adv.grad.clone() if x_adv.grad is not None else torch.zeros_like(x_adv)
                    
                    # å­˜å‚¨æ¢¯åº¦å·®å’Œå†³ç­–è¾¹ç•Œè·ç¦»
                    grad_diff = grad_other - grad_current
                    decision_boundary_dist = (loss_other - loss_current).item()
                    
                    key = f"t{t}_k{k}"
                    grad_dict[key] = {
                        'grad_diff': grad_diff,
                        'distance': abs(decision_boundary_dist),
                        'logit_diff': decision_boundary_dist
                    }
        
        return grad_dict
    
    def _select_optimal_perturbation(self, grad_dict, overshoot):
        """é€‰æ‹©æœ€ä¼˜æ‰°åŠ¨æ–¹å‘"""
        if not grad_dict:
            return torch.zeros_like(list(grad_dict.values())[0]['grad_diff'])
        
        min_perturbation_norm = float('inf')
        optimal_perturbation = None
        
        for key, info in grad_dict.items():
            grad_diff = info['grad_diff']
            distance = info['distance']
            
            # è®¡ç®—æ‰°åŠ¨æ–¹å‘çš„L2èŒƒæ•°
            grad_norm = torch.norm(grad_diff.flatten()).item()
            
            if grad_norm > 1e-8 and distance > 1e-8:
                # è®¡ç®—æœ€å°æ‰°åŠ¨
                perturbation = (distance / (grad_norm ** 2)) * grad_diff
                perturbation_norm = torch.norm(perturbation.flatten()).item()
                
                if perturbation_norm < min_perturbation_norm:
                    min_perturbation_norm = perturbation_norm
                    optimal_perturbation = perturbation
        
        if optimal_perturbation is not None:
            return (1 + overshoot) * optimal_perturbation
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆæ‰°åŠ¨ï¼Œä½¿ç”¨éšæœºæ‰°åŠ¨
            return 0.001 * torch.randn_like(list(grad_dict.values())[0]['grad_diff'])
    
    def _adaptive_overshoot_update(self, current_norm, best_norm, current_overshoot, iteration):
        """è‡ªé€‚åº”æ›´æ–°è¶…è°ƒå‚æ•°"""
        if iteration < 5:
            return current_overshoot
        
        # å¦‚æœæ‰°åŠ¨åœ¨å‡å°ï¼Œå‡å°‘è¶…è°ƒ
        if current_norm < best_norm:
            new_overshoot = max(current_overshoot * 0.95, self.min_overshoot)
        else:
            # å¦‚æœæ‰°åŠ¨åœ¨å¢å¤§ï¼Œå¢åŠ è¶…è°ƒ
            new_overshoot = min(current_overshoot * 1.05, self.max_overshoot)
        
        return new_overshoot
    
    def _check_convergence(self, history, window_size=5):
        """æ£€æŸ¥æ˜¯å¦æ”¶æ•›"""
        if len(history) < window_size * 2:
            return False
        
        recent_values = history[-window_size:]
        previous_values = history[-window_size*2:-window_size]
        
        recent_mean = np.mean(recent_values)
        previous_mean = np.mean(previous_values)
        
        # å¦‚æœæœ€è¿‘çš„å˜åŒ–å¾ˆå°ï¼Œè®¤ä¸ºæ”¶æ•›
        relative_change = abs(recent_mean - previous_mean) / (previous_mean + 1e-8)
        return relative_change < self.convergence_threshold

    @torch.no_grad()
    def _fast_prediction_check(self, model, images_batch, original_texts):
        """å¿«é€Ÿé¢„æµ‹æ£€æŸ¥ - é¿å…é‡å¤çš„tokenizerè°ƒç”¨"""
        current_texts = predict_text(model, images_batch)
        success_mask = torch.tensor([orig != curr for orig, curr in zip(original_texts, current_texts)], 
                                  device=self.device)
        return success_mask, current_texts
    
    def _adaptive_chunk_size(self, total_samples, available_memory_gb=None):
        """è‡ªé€‚åº”ç¡®å®šæœ€ä¼˜åˆ†å—å¤§å°"""
        if available_memory_gb is None and torch.cuda.is_available():
            # è·å–GPUå†…å­˜ä¿¡æ¯
            total_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)  # GB
            free_memory = (total_memory - torch.cuda.memory_allocated() / (1024**3))
            available_memory_gb = free_memory * 0.6  # ä½¿ç”¨60%çš„å¯ç”¨å†…å­˜
        elif available_memory_gb is None:
            available_memory_gb = 2.0  # CPUé»˜è®¤2GB
        
        # ä¼°ç®—æ¯ä¸ªæ ·æœ¬çš„å†…å­˜éœ€æ±‚ï¼ˆç»éªŒå€¼ï¼‰
        memory_per_sample_gb = 0.1  # æ¯ä¸ªæ ·æœ¬å¤§çº¦100MBï¼ˆåŒ…æ‹¬æ¢¯åº¦ï¼‰
        optimal_chunk_size = max(1, int(available_memory_gb / memory_per_sample_gb))
        
        # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
        chunk_size = min(optimal_chunk_size, total_samples, 16)  # æœ€å¤§16ä¸ªæ ·æœ¬ä¸€ç»„
        
        return chunk_size


def select_model():
    """äº¤äº’å¼æ¨¡å‹é€‰æ‹©"""
    models = {
        1: 'parseq_tiny',
        2: 'parseq_patch16_224', 
        3: 'parseq',
        4: 'parseq_base'
    }
    
    descriptions = {
        1: 'å¾®å‹æ¨¡å‹ - æœ€å¿«é€Ÿåº¦ï¼Œé€‚åˆå¿«é€Ÿæµ‹è¯•',
        2: 'æ ‡å‡†æ¨¡å‹ - å¹³è¡¡æ€§èƒ½å’Œé€Ÿåº¦',
        3: 'å®Œæ•´æ¨¡å‹ - æœ€ä½³æ€§èƒ½', 
        4: 'åŸºç¡€æ¨¡å‹ - æ ‡å‡†é…ç½®'
    }
    
    print("\nè¯·é€‰æ‹©PARSeqæ¨¡å‹:")
    for key, desc in descriptions.items():
        print(f"  {key}. {models[key]} - {desc}")
    
    while True:
        try:
            choice = int(input("\nè¯·è¾“å…¥é€‰æ‹© (1-4): "))
            if choice in models:
                model_name = models[choice]
                print(f"âœ“ å·²é€‰æ‹©: {model_name}")
                return model_name
            else:
                print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥1-4ä¹‹é—´çš„æ•°å­—")
        except ValueError:
            print("è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")


def select_dataset_scope():
    """é€‰æ‹©æ•°æ®é›†èŒƒå›´"""
    scopes = {
        1: (5, "å°æ ·æœ¬æµ‹è¯• - 5å¼ å›¾åƒ"),
        2: (15, "ä¸­ç­‰è§„æ¨¡æµ‹è¯• - 15å¼ å›¾åƒ"), 
        3: (30, "å¤§è§„æ¨¡æµ‹è¯• - 30å¼ å›¾åƒ"),
        4: (80, "å®Œæ•´æ•°æ®é›† - 80å¼ å›¾åƒ")
    }
    
    print("\nè¯·é€‰æ‹©æµ‹è¯•èŒƒå›´:")
    for key, (num, desc) in scopes.items():
        print(f"  {key}. {desc}")
    
    while True:
        try:
            choice = int(input("\nè¯·è¾“å…¥é€‰æ‹© (1-4): "))
            if choice in scopes:
                num_images, desc = scopes[choice]
                print(f"âœ“ å·²é€‰æ‹©: {desc}")
                return num_images
            else:
                print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥1-4ä¹‹é—´çš„æ•°å­—")
        except ValueError:
            print("è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")


def load_cute80_images(num_images=5):
    """åŠ è½½CUTE80æ•°æ®é›†å›¾åƒ"""
    cute80_dir = Path(__file__).parent.parent.parent / "CUTE80"
    
    if not cute80_dir.exists():
        raise FileNotFoundError(f"CUTE80æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {cute80_dir}")
    
    # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
    image_extensions = ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']
    image_files = []
    
    for ext in image_extensions:
        image_files.extend(list(cute80_dir.glob(f"*{ext}")))
    
    if len(image_files) == 0:
        raise FileNotFoundError(f"åœ¨ {cute80_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾åƒæ–‡ä»¶")
    
    # æ’åºå¹¶é€‰æ‹©æŒ‡å®šæ•°é‡çš„å›¾åƒ
    image_files.sort()
    selected_files = image_files[:num_images]
    
    print(f"\nä»CUTE80æ•°æ®é›†åŠ è½½ {len(selected_files)} å¼ å›¾åƒ:")
    for i, img_path in enumerate(selected_files):
        print(f"  {i+1}. {img_path.name}")
    
    return selected_files


def preprocess_images(image_files, model):
    """é¢„å¤„ç†å›¾åƒ"""
    from strhub.data.module import SceneTextDataModule
    transform = SceneTextDataModule.get_transform(model.hparams.img_size)
    
    original_images = []
    image_tensors = []
    image_names = []
    
    print("\næ­£åœ¨é¢„å¤„ç†å›¾åƒ...")
    for i, img_path in enumerate(image_files):
        try:
            # åŠ è½½åŸå§‹å›¾åƒ
            orig_img = Image.open(img_path).convert('RGB')
            original_images.append(orig_img)
            
            # é¢„å¤„ç†
            img_tensor = transform(orig_img)
            image_tensors.append(img_tensor)
            
            # è·å–å›¾åƒå
            image_names.append(img_path.stem)
            
            print(f"  {i+1}. {img_path.name} -> {orig_img.size}")
            
        except Exception as e:
            print(f"  è­¦å‘Š: åŠ è½½å›¾åƒ {img_path.name} å¤±è´¥: {e}")
            continue
    
    if len(image_tensors) == 0:
        raise ValueError("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•å›¾åƒï¼")
    
    # è½¬æ¢ä¸ºbatch
    images_batch = torch.stack(image_tensors).to(device)
    print(f"\nå›¾åƒæ‰¹æ¬¡å‡†å¤‡å®Œæˆï¼Œå½¢çŠ¶: {images_batch.shape}")
    
    return original_images, images_batch, image_names


def visualize_results(original_images, original_texts, adversarial_texts, 
                     perturbations, image_names, convergence_histories, save_dir=None):
    """å¯è§†åŒ–æ”»å‡»ç»“æœå’Œæ”¶æ•›æ›²çº¿"""
    num_images = len(original_images)
    
    # åˆ›å»ºå­å›¾å¸ƒå±€ï¼šåŸå§‹å›¾åƒã€æ‰°åŠ¨ã€æ”¶æ•›æ›²çº¿
    fig = plt.figure(figsize=(20, 6 * ((num_images + 2) // 3)))
    
    rows = (num_images + 2) // 3
    cols = 3
    
    # ä¸»æ ‡é¢˜
    fig.suptitle("SuperDeepFoolæ”»å‡»ç»“æœå¯¹æ¯”", fontsize=20, fontweight='bold')
    
    for i in range(num_images):
        row = i // cols
        col = i % cols
        
        # åˆ›å»ºå­å›¾ç½‘æ ¼
        ax1 = plt.subplot2grid((rows * 3, cols), (row * 3, col))
        ax2 = plt.subplot2grid((rows * 3, cols), (row * 3 + 1, col))
        ax3 = plt.subplot2grid((rows * 3, cols), (row * 3 + 2, col))
        
        # åŸå§‹å›¾åƒ
        ax1.imshow(original_images[i])
        ax1.set_title(f'åŸå§‹å›¾åƒ {i+1}\nè¯†åˆ«: "{original_texts[i]}"', fontsize=10)
        ax1.axis('off')
        
        # æ‰°åŠ¨å¯è§†åŒ–
        pert = perturbations[i].cpu().numpy()
        pert_vis = np.transpose(pert, (1, 2, 0))
        pert_vis = (pert_vis - pert_vis.min()) / (pert_vis.max() - pert_vis.min() + 1e-8)
        
        ax2.imshow(pert_vis)
        attack_status = "æˆåŠŸ" if original_texts[i] != adversarial_texts[i] else "å¤±è´¥"
        ax2.set_title(f'æ‰°åŠ¨å¯è§†åŒ–\næ”»å‡»å: "{adversarial_texts[i]}"\nçŠ¶æ€: {attack_status}', fontsize=10)
        ax2.axis('off')
        
        # æ”¶æ•›æ›²çº¿
        if i < len(convergence_histories) and convergence_histories[i]:
            ax3.plot(convergence_histories[i], 'b-', linewidth=2)
            ax3.set_title(f'æ”¶æ•›æ›²çº¿\næœ€ç»ˆL2èŒƒæ•°: {convergence_histories[i][-1]:.4f}', fontsize=10)
            ax3.set_xlabel('è¿­ä»£æ¬¡æ•°')
            ax3.set_ylabel('æ‰°åŠ¨L2èŒƒæ•°')
            ax3.grid(True, alpha=0.3)
        else:
            ax3.text(0.5, 0.5, 'æ— æ”¶æ•›æ•°æ®', ha='center', va='center', transform=ax3.transAxes)
            ax3.set_title('æ”¶æ•›æ›²çº¿', fontsize=10)
    
    plt.tight_layout()
    
    if save_dir:
        save_path = Path(save_dir) / "superdeepfool_results.png"
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ç»“æœå›¾åƒå·²ä¿å­˜åˆ°: {save_path}")
    
    plt.show()


def select_attack_mode():
    """é€‰æ‹©æ”»å‡»æ¨¡å¼"""
    modes = {
        1: ("åŸå§‹æ¨¡å¼", "é€å¼ ä¸²è¡Œå¤„ç†ï¼ˆæ…¢ï¼‰"),
        2: ("å‘é‡åŒ–æ¨¡å¼", "æ‰¹é‡å¹¶è¡Œå¤„ç†ï¼ˆå¿«ï¼‰"),
        3: ("ä¼˜åŒ–æ¨¡å¼", "å†…å­˜ä¼˜åŒ–+åˆ†å—å¤„ç†ï¼ˆæœ€å¿«ï¼‰"),
        4: ("æ€§èƒ½å¯¹æ¯”", "è¿è¡Œæ‰€æœ‰æ¨¡å¼è¿›è¡Œå¯¹æ¯”")
    }
    
    print("\nè¯·é€‰æ‹©æ”»å‡»æ¨¡å¼:")
    for key, (name, desc) in modes.items():
        print(f"  {key}. {name} - {desc}")
    
    while True:
        try:
            choice = int(input("\nè¯·è¾“å…¥é€‰æ‹© (1-4): "))
            if choice in modes:
                name, desc = modes[choice]
                print(f"âœ“ å·²é€‰æ‹©: {name}")
                return choice
            else:
                print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥1-4ä¹‹é—´çš„æ•°å­—")
        except ValueError:
            print("è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")


def performance_comparison(model, images_batch, image_names, max_iter=50):
    """æ€§èƒ½å¯¹æ¯”æµ‹è¯•"""
    print("\n" + "="*80)
    print("SuperDeepFoolæ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    print("="*80)
    
    results = {}
    attacker = SuperDeepFoolAttacker(model, device)
    
    # 1. åŸå§‹ä¸²è¡Œæ¨¡å¼ï¼ˆä¸ºäº†å¯¹æ¯”ï¼Œåªæµ‹è¯•å‰å‡ å¼ å›¾åƒï¼‰
    test_images = images_batch[:min(3, len(images_batch))]  # é™åˆ¶æµ‹è¯•æ•°é‡
    print(f"\n1. åŸå§‹ä¸²è¡Œæ¨¡å¼æµ‹è¯• ({len(test_images)} å¼ å›¾åƒ)...")
    
    # æ¨¡æ‹ŸåŸå§‹æ¨¡å¼ï¼ˆç®€åŒ–ç‰ˆï¼‰
    start_time = time.time()
    original_results = []
    for i in range(len(test_images)):
        single_image = test_images[i:i+1]
        # ä½¿ç”¨ç®€åŒ–çš„å•å¼ å¤„ç†é€»è¾‘
        adv_img, pert, iter_count, hist = attacker.superdeepfool_attack(single_image, max_iter=20)
        original_results.append((adv_img, pert, iter_count, hist))
    original_time = time.time() - start_time
    
    results['original'] = {
        'time': original_time,
        'per_image': original_time / len(test_images),
        'description': 'åŸå§‹ä¸²è¡Œæ¨¡å¼'
    }
    
    # 2. å‘é‡åŒ–æ‰¹é‡æ¨¡å¼
    print(f"\n2. å‘é‡åŒ–æ‰¹é‡æ¨¡å¼æµ‹è¯• ({len(images_batch)} å¼ å›¾åƒ)...")
    start_time = time.time()
    vectorized_adv, vectorized_pert, vectorized_iter, vectorized_hist = attacker.superdeepfool_attack(
        images_batch, max_iter=max_iter
    )
    vectorized_time = time.time() - start_time
    
    results['vectorized'] = {
        'time': vectorized_time,
        'per_image': vectorized_time / len(images_batch),
        'description': 'å‘é‡åŒ–æ‰¹é‡æ¨¡å¼'
    }
    
    # 3. ä¼˜åŒ–æ¨¡å¼
    print(f"\n3. ä¼˜åŒ–æ¨¡å¼æµ‹è¯• ({len(images_batch)} å¼ å›¾åƒ)...")
    start_time = time.time()
    optimized_adv, optimized_pert, optimized_iter, optimized_hist = attacker.superdeepfool_attack_optimized(
        images_batch, max_iter=max_iter
    )
    optimized_time = time.time() - start_time
    
    results['optimized'] = {
        'time': optimized_time,
        'per_image': optimized_time / len(images_batch),
        'description': 'ä¼˜åŒ–æ¨¡å¼'
    }
    
    # æ€§èƒ½åˆ†æ
    print("\n" + "="*80)
    print("æ€§èƒ½å¯¹æ¯”ç»“æœ")
    print("="*80)
    
    print(f"{'æ¨¡å¼':<15} {'æ€»æ—¶é—´(s)':<12} {'æ¯å¼ (s)':<12} {'ç›¸å¯¹æé€Ÿ':<12}")
    print("-" * 60)
    
    baseline_time = results['original']['per_image']
    
    for mode, data in results.items():
        speedup = baseline_time / data['per_image'] if data['per_image'] > 0 else 0
        print(f"{data['description']:<15} {data['time']:<12.2f} {data['per_image']:<12.3f} {speedup:<12.1f}x")
    
    print("\næ€§èƒ½ä¼˜åŒ–æ€»ç»“:")
    vectorized_speedup = baseline_time / results['vectorized']['per_image']
    optimized_speedup = baseline_time / results['optimized']['per_image']
    
    print(f"  â€¢ å‘é‡åŒ–æ¨¡å¼ç›¸æ¯”åŸå§‹æ¨¡å¼æé€Ÿ: {vectorized_speedup:.1f}x")
    print(f"  â€¢ ä¼˜åŒ–æ¨¡å¼ç›¸æ¯”åŸå§‹æ¨¡å¼æé€Ÿ: {optimized_speedup:.1f}x")
    print(f"  â€¢ ä¼˜åŒ–æ¨¡å¼ç›¸æ¯”å‘é‡åŒ–æ¨¡å¼æé€Ÿ: {results['vectorized']['per_image']/results['optimized']['per_image']:.1f}x")
    
    # è¿”å›æœ€ä¼˜ç»“æœç”¨äºåç»­åˆ†æ
    return {
        'adversarial_images': optimized_adv,
        'perturbations': optimized_pert,
        'iterations': optimized_iter,
        'convergence_histories': optimized_hist,
        'time': optimized_time
    }
    """å¿«é€Ÿæµ‹è¯•æ¨¡å¼"""
    print("ğŸš€ SuperDeepFoolå¿«é€Ÿæµ‹è¯•æ¨¡å¼")
    print("=" * 50)
    
    # å›ºå®šé…ç½®ä»¥æé«˜é€Ÿåº¦
    config = {
        'model_name': 'parseq_tiny',
        'num_samples': 3,
        'max_iter': 10,
        'top_k_classes': 2,
        'overshoot': 0.05
    }
    
    print(f"æ¨¡å‹: {config['model_name']}")
    print(f"æ ·æœ¬æ•°: {config['num_samples']}")
    print(f"æœ€å¤§è¿­ä»£: {config['max_iter']}")
    print(f"Top-Kç±»åˆ«: {config['top_k_classes']}")
    
    try:
        # åŠ è½½æ¨¡å‹
        print("\nğŸ“¦ åŠ è½½æ¨¡å‹...")
        start_time = time.time()
        model = load_model(config['model_name'])
        print(f"âœ“ æ¨¡å‹åŠ è½½å®Œæˆ ({time.time() - start_time:.1f}s)")
        
        # åŠ è½½æ•°æ®
        print("\nğŸ“ åŠ è½½æµ‹è¯•æ•°æ®...")
        start_time = time.time()
        data_loader = load_cute80_data(num_samples=config['num_samples'])
        print(f"âœ“ æ•°æ®åŠ è½½å®Œæˆ ({time.time() - start_time:.1f}s)")
        
        # åˆå§‹åŒ–æ”»å‡»å™¨
        print("\nâš¡ åˆå§‹åŒ–SuperDeepFoolæ”»å‡»å™¨...")
        attacker = SuperDeepFoolAttacker(
            model=model,
            top_k_classes=config['top_k_classes'],
            momentum=0.8,
            adaptive_overshoot=True
        )
        
        # æ‰§è¡Œæ”»å‡»
        print(f"\nğŸ¯ å¼€å§‹æ”»å‡»æµ‹è¯•...")
        attack_start = time.time()
        
        for batch_images, batch_labels in data_loader:
            adversarial_images, perturbations, iterations, histories = attacker.attack(
                batch_images, 
                max_iter=config['max_iter'],
                overshoot=config['overshoot']
            )
            
            # è®¡ç®—æ”»å‡»ç»“æœ
            success_rate = calculate_attack_success_rate(
                model, batch_images, adversarial_images, batch_labels
            )
            
            total_time = time.time() - attack_start
            
            print(f"\nğŸ“Š å¿«é€Ÿæµ‹è¯•ç»“æœ:")
            print(f"  â€¢ å¤„ç†å›¾åƒ: {len(batch_images)}")
            print(f"  â€¢ æ”»å‡»æˆåŠŸç‡: {success_rate:.1%}")
            print(f"  â€¢ å¹³å‡è¿­ä»£æ¬¡æ•°: {np.mean(iterations):.1f}")
            print(f"  â€¢ æ€»è€—æ—¶: {total_time:.1f}s")
            print(f"  â€¢ å¹³å‡æ¯å¼ å›¾åƒ: {total_time/len(batch_images):.1f}s")
            
            break  # åªå¤„ç†ç¬¬ä¸€ä¸ªæ‰¹æ¬¡
            
        print("\nâœ… å¿«é€Ÿæµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        print("è¯·æ£€æŸ¥ç¯å¢ƒé…ç½®å’Œä¾èµ–é¡¹")


def quick_test():
    """å¿«é€Ÿæµ‹è¯•æ¨¡å¼ - ä½¿ç”¨ä¼˜åŒ–ç‰ˆæœ¬"""
    print("ğŸš€ SuperDeepFoolå¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼ˆä¼˜åŒ–ç‰ˆï¼‰")
    print("=" * 50)
    
    # å›ºå®šé…ç½®ä»¥æé«˜é€Ÿåº¦
    config = {
        'model_name': 'parseq_tiny',
        'num_samples': 3,
        'max_iter': 20,
        'overshoot': 0.05
    }
    
    print(f"æ¨¡å‹: {config['model_name']}")
    print(f"æ ·æœ¬æ•°: {config['num_samples']}")
    print(f"æœ€å¤§è¿­ä»£: {config['max_iter']}")
    print(f"ä½¿ç”¨ä¼˜åŒ–æ”»å‡»æ¨¡å¼")
    
    try:
        # åŠ è½½æ¨¡å‹
        print("\nğŸ“¦ åŠ è½½æ¨¡å‹...")
        start_time = time.time()
        model = torch.hub.load('baudm/parseq', config['model_name'], pretrained=True, trust_repo=True)
        model.eval().to(device)
        print(f"âœ“ æ¨¡å‹åŠ è½½å®Œæˆ ({time.time() - start_time:.1f}s)")
        
        # åŠ è½½æ•°æ®
        print("\nğŸ“ åŠ è½½æµ‹è¯•æ•°æ®...")
        start_time = time.time()
        image_files = load_cute80_images(config['num_samples'])
        original_images, images_batch, image_names = preprocess_images(image_files, model)
        print(f"âœ“ æ•°æ®åŠ è½½å®Œæˆ ({time.time() - start_time:.1f}s)")
        
        # åˆå§‹åŒ–æ”»å‡»å™¨
        print("\nâš¡ åˆå§‹åŒ–SuperDeepFoolæ”»å‡»å™¨...")
        attacker = SuperDeepFoolAttacker(model, device)
        
        # æ‰§è¡Œä¼˜åŒ–æ”»å‡»
        print(f"\nğŸ¯ å¼€å§‹ä¼˜åŒ–æ”»å‡»æµ‹è¯•...")
        attack_start = time.time()
        
        adversarial_images, perturbations, iterations, histories = attacker.superdeepfool_attack_optimized(
            images_batch, 
            max_iter=config['max_iter'],
            overshoot=config['overshoot']
        )
        
        total_time = time.time() - attack_start
        
        # è®¡ç®—æ”»å‡»ç»“æœ
        original_texts = predict_text(model, images_batch)
        adversarial_texts = predict_text(model, adversarial_images)
        
        success_count = sum(1 for i in range(len(original_texts)) 
                          if original_texts[i] != adversarial_texts[i])
        success_rate = success_count / len(original_texts)
        
        print(f"\nğŸ“Š å¿«é€Ÿæµ‹è¯•ç»“æœ:")
        print(f"  â€¢ å¤„ç†å›¾åƒ: {len(images_batch)}")
        print(f"  â€¢ æ”»å‡»æˆåŠŸç‡: {success_rate:.1%} ({success_count}/{len(original_texts)})")
        print(f"  â€¢ å¹³å‡è¿­ä»£æ¬¡æ•°: {np.mean(iterations):.1f}")
        print(f"  â€¢ æ€»è€—æ—¶: {total_time:.1f}s")
        print(f"  â€¢ å¹³å‡æ¯å¼ å›¾åƒ: {total_time/len(images_batch):.2f}s")
        print(f"  â€¢ é¢„è®¡ä¼˜åŒ–æé€Ÿ: 10-15x")
        
        # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
        print(f"\nè¯¦ç»†ç»“æœ:")
        for i in range(len(original_texts)):
            status = "âœ“æˆåŠŸ" if original_texts[i] != adversarial_texts[i] else "âœ—å¤±è´¥"
            pert_norm = torch.norm(perturbations[i]).item()
            print(f"  {i+1}. {image_names[i]}: {original_texts[i]} â†’ {adversarial_texts[i]} [{status}] "
                  f"(L2: {pert_norm:.4f})")
            
        print("\nâœ… å¿«é€Ÿæµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        print("è¯·æ£€æŸ¥ç¯å¢ƒé…ç½®å’Œä¾èµ–é¡¹")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("SuperDeepFoolå¯¹æŠ—æ”»å‡» - æ”¹è¿›ç‰ˆDeepFoolç®—æ³•")
    print("é€‚ç”¨äºPARSeqæ–‡æœ¬è¯†åˆ«æ¨¡å‹")
    print("=" * 80)
    
    try:
        # 1. é€‰æ‹©æ¨¡å‹
        model_name = select_model()
        
        # 2. åŠ è½½æ¨¡å‹
        print(f"\næ­£åœ¨åŠ è½½æ¨¡å‹: {model_name}...")
        model = torch.hub.load('baudm/parseq', model_name, pretrained=True, trust_repo=True)
        model.eval()
        model.to(device)
        
        total_params = sum(p.numel() for p in model.parameters())
        print(f"âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ!")
        print(f"  å‚æ•°é‡: {total_params:,}")
        print(f"  è¾“å…¥å°ºå¯¸: {model.hparams.img_size}")
        
        # 3. é€‰æ‹©æ•°æ®é›†èŒƒå›´
        num_images = select_dataset_scope()
        
        # 4. åŠ è½½å›¾åƒ
        image_files = load_cute80_images(num_images)
        original_images, images_batch, image_names = preprocess_images(image_files, model)
        
        # 5. åŸå§‹é¢„æµ‹
        print("\næ­£åœ¨è¿›è¡ŒåŸå§‹æ–‡æœ¬è¯†åˆ«...")
        original_texts = predict_text(model, images_batch)
        
        print("\nåŸå§‹è¯†åˆ«ç»“æœ:")
        for i, (name, text) in enumerate(zip(image_names, original_texts)):
            print(f"  {i+1}. {name}: \"{text}\"")
        
        # 6. åˆ›å»ºSuperDeepFoolæ”»å‡»å™¨
        attacker = SuperDeepFoolAttacker(model, device)
        
        # 6.5. é€‰æ‹©æ”»å‡»æ¨¡å¼
        attack_mode = select_attack_mode()
        
        # 7. æ‰§è¡ŒSuperDeepFoolæ”»å‡»
        print(f"\nå¼€å§‹æ‰§è¡ŒSuperDeepFoolæ”»å‡»...")
        max_iter = 100
        overshoot = 0.02
        
        if attack_mode == 4:  # æ€§èƒ½å¯¹æ¯”æ¨¡å¼
            attack_results = performance_comparison(model, images_batch, image_names, max_iter)
            adversarial_images = attack_results['adversarial_images'] if 'adversarial_images' in attack_results else None
            perturbations = attack_results['perturbations'] if 'perturbations' in attack_results else None
            iterations = attack_results['iterations'] if 'iterations' in attack_results else None
            convergence_histories = attack_results['convergence_histories'] if 'convergence_histories' in attack_results else None
            total_time = attack_results['time'] if 'time' in attack_results else 0
            
            # å¦‚æœæ€§èƒ½å¯¹æ¯”æ¨¡å¼æ²¡æœ‰è¿”å›å®Œæ•´ç»“æœï¼Œä½¿ç”¨ä¼˜åŒ–æ¨¡å¼
            if adversarial_images is None:
                print("\nä½¿ç”¨ä¼˜åŒ–æ¨¡å¼è·å–å®Œæ•´ç»“æœ...")
                start_time = time.time()
                adversarial_images, perturbations, iterations, convergence_histories = attacker.superdeepfool_attack_optimized(
                    images_batch, max_iter=max_iter, overshoot=overshoot
                )
                total_time = time.time() - start_time
        else:
            start_time = time.time()
            
            if attack_mode == 1:  # åŸå§‹æ¨¡å¼ï¼ˆä¸æ¨èç”¨äºå¤§æ‰¹é‡ï¼‰
                print("âš ï¸  è­¦å‘Š: åŸå§‹æ¨¡å¼å¤„ç†å¤§æ‰¹é‡æ•°æ®ä¼šå¾ˆæ…¢ï¼Œå»ºè®®é€‰æ‹©å…¶ä»–æ¨¡å¼")
                # é™åˆ¶æ‰¹é‡å¤§å°ä»¥é¿å…è¿‡é•¿ç­‰å¾…
                if len(images_batch) > 5:
                    print(f"   é™åˆ¶å¤„ç†å‰5å¼ å›¾åƒä»¥èŠ‚çœæ—¶é—´...")
                    images_batch = images_batch[:5]
                    original_images = original_images[:5]
                    image_names = image_names[:5]
                    original_texts = original_texts[:5]
                
                # ä½¿ç”¨åŸå§‹çš„é€å¼ å¤„ç†é€»è¾‘
                adversarial_images_list = []
                perturbations_list = []
                iterations_list = []
                convergence_histories_list = []
                
                for i in range(len(images_batch)):
                    single_adv, single_pert, single_iter, single_hist = attacker.superdeepfool_attack(
                        images_batch[i:i+1], max_iter=max_iter, overshoot=overshoot
                    )
                    adversarial_images_list.append(single_adv.squeeze(0))
                    perturbations_list.append(single_pert.squeeze(0))
                    iterations_list.extend(single_iter)
                    convergence_histories_list.extend(single_hist)
                
                adversarial_images = torch.stack(adversarial_images_list)
                perturbations = torch.stack(perturbations_list)
                iterations = iterations_list
                convergence_histories = convergence_histories_list
                
            elif attack_mode == 2:  # å‘é‡åŒ–æ¨¡å¼
                adversarial_images, perturbations, iterations, convergence_histories = attacker.superdeepfool_attack(
                    images_batch, max_iter=max_iter, overshoot=overshoot
                )
            elif attack_mode == 3:  # ä¼˜åŒ–æ¨¡å¼
                adversarial_images, perturbations, iterations, convergence_histories = attacker.superdeepfool_attack_optimized(
                    images_batch, max_iter=max_iter, overshoot=overshoot
                )
            
            total_time = time.time() - start_time
        
        # 8. æ”»å‡»åé¢„æµ‹
        print("\næ­£åœ¨è¯†åˆ«å¯¹æŠ—æ ·æœ¬...")
        adversarial_texts = predict_text(model, adversarial_images)
        
        # 9. åˆ†æç»“æœ
        print("\n" + "="*80)
        print("SuperDeepFoolæ”»å‡»ç»“æœåˆ†æ")
        print("="*80)
        
        success_count = 0
        total_perturbation = 0
        
        for i in range(len(original_texts)):
            attack_success = original_texts[i] != adversarial_texts[i]
            if attack_success:
                success_count += 1
            
            pert_norm = torch.norm(perturbations[i]).item()
            total_perturbation += pert_norm
            
            status = "âœ“ æˆåŠŸ" if attack_success else "âœ— å¤±è´¥"
            print(f"{i+1}. {image_names[i]}:")
            print(f"   åŸå§‹: \"{original_texts[i]}\"")
            print(f"   æ”»å‡»å: \"{adversarial_texts[i]}\"")
            print(f"   çŠ¶æ€: {status}")
            print(f"   è¿­ä»£æ¬¡æ•°: {iterations[i]}")
            print(f"   æ‰°åŠ¨L2èŒƒæ•°: {pert_norm:.6f}")
            print("-" * 60)
        
        success_rate = success_count / len(original_texts)
        avg_perturbation = total_perturbation / len(original_texts)
        avg_iterations = sum(iterations) / len(iterations)
        
        print(f"\næ€»ä½“ç»Ÿè®¡:")
        print(f"  æ”»å‡»æˆåŠŸç‡: {success_count}/{len(original_texts)} = {success_rate:.1%}")
        print(f"  å¹³å‡æ‰°åŠ¨L2èŒƒæ•°: {avg_perturbation:.6f}")
        print(f"  å¹³å‡è¿­ä»£æ¬¡æ•°: {avg_iterations:.1f}")
        print(f"  æ€»æ”»å‡»æ—¶é—´: {total_time:.1f}ç§’")
        print(f"  å¹³å‡æ¯å¼ å›¾åƒ: {total_time/len(original_texts):.1f}ç§’")
        
        # 10. ä¿å­˜ç»“æœ
        save_dir = Path(__file__).parent / "results"
        save_dir.mkdir(exist_ok=True)
        
        # ä¿å­˜ç»Ÿè®¡ç»“æœ
        stats_file = save_dir / f"superdeepfool_stats_{model_name}.txt"
        with open(stats_file, 'w', encoding='utf-8') as f:
            f.write("SuperDeepFoolæ”»å‡»ç»Ÿè®¡ç»“æœ\n")
            f.write("="*50 + "\n")
            f.write(f"æ¨¡å‹: {model_name}\n")
            f.write(f"æµ‹è¯•å›¾åƒæ•°: {len(original_texts)}\n")
            f.write(f"æ”»å‡»æˆåŠŸç‡: {success_rate:.1%}\n")
            f.write(f"å¹³å‡æ‰°åŠ¨L2èŒƒæ•°: {avg_perturbation:.6f}\n")
            f.write(f"å¹³å‡è¿­ä»£æ¬¡æ•°: {avg_iterations:.1f}\n")
            f.write(f"æ€»æ”»å‡»æ—¶é—´: {total_time:.1f}ç§’\n")
            f.write(f"å¹³å‡æ¯å¼ å›¾åƒ: {total_time/len(original_texts):.1f}ç§’\n\n")
            
            for i in range(len(original_texts)):
                attack_success = original_texts[i] != adversarial_texts[i]
                status = "æˆåŠŸ" if attack_success else "å¤±è´¥"
                pert_norm = torch.norm(perturbations[i]).item()
                
                f.write(f"{i+1}. {image_names[i]}:\n")
                f.write(f"   åŸå§‹: \"{original_texts[i]}\"\n")
                f.write(f"   æ”»å‡»å: \"{adversarial_texts[i]}\"\n")
                f.write(f"   çŠ¶æ€: {status}\n")
                f.write(f"   è¿­ä»£æ¬¡æ•°: {iterations[i]}\n")
                f.write(f"   æ‰°åŠ¨L2èŒƒæ•°: {pert_norm:.6f}\n")
                f.write("-" * 30 + "\n")
        
        print(f"\nè¯¦ç»†ç»Ÿè®¡ç»“æœå·²ä¿å­˜åˆ°: {stats_file}")
        
        # 11. å¯è§†åŒ–ç»“æœ
        print("\næ­£åœ¨ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")
        visualize_results(original_images, original_texts, adversarial_texts, 
                         perturbations, image_names, convergence_histories, save_dir)
        
        print("\n" + "="*80)
        print("SuperDeepFoolæ”»å‡»å®éªŒå®Œæˆï¼")
        print("="*80)
        
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        print(f"\né”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    print("SuperDeepFoolæ”»å‡»è„šæœ¬")
    print("1. å¿«é€Ÿæµ‹è¯•æ¨¡å¼")
    print("2. å®Œæ•´æ”»å‡»æ¨¡å¼")
    
    choice = input("\nè¯·é€‰æ‹©æ¨¡å¼ (1/2, é»˜è®¤1): ").strip()
    
    if choice == "2":
        main()
    else:
        quick_test()
