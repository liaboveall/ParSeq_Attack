#!/usr/bin/env python3
"""
AutoAttackæ”»å‡»ç®—æ³•åœ¨åœºæ™¯æ–‡æœ¬è¯†åˆ«æ¨¡å‹ä¸­çš„å®ç°ã€‚
è¯¥è„šæœ¬æä¾›äº†å„ç§AutoAttacké…ç½®ç”¨äºè¯„ä¼°æ–‡æœ¬è¯†åˆ«æ¨¡å‹çš„é²æ£’æ€§ã€‚
"""

import os
import sys
import string
import torch
import torch.nn.functional as F
from pathlib import Path
from tqdm import tqdm
import warnings

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥é¡¹ç›®æ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from strhub.models.utils import load_from_checkpoint
from strhub.data.module import SceneTextDataModule

try:
    print("å°è¯•å¯¼å…¥AutoAttack...")
    from autoattack import AutoAttack
    print("âœ… AutoAttackå¯¼å…¥æˆåŠŸï¼")
except ImportError as e:
    print(f"âŒ AutoAttackå¯¼å…¥å¤±è´¥: {e}")
    print("è¯·å…ˆå®‰è£…ï¼š")
    print("pip install git+https://github.com/fra31/auto-attack")
    sys.exit(1)
except Exception as e:
    print(f"âŒ å¯¼å…¥AutoAttackæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)


class TextRecognitionModelWrapper:
    """
    æ–‡æœ¬è¯†åˆ«æ¨¡å‹åŒ…è£…å™¨ç±»ï¼Œç”¨äºé€‚é…AutoAttackã€‚
    AutoAttackæœŸæœ›ä¸€ä¸ªæ¥æ”¶å›¾åƒå¹¶è¿”å›logitsçš„å‰å‘å‡½æ•°ã€‚
    """
    
    def __init__(self, model, device='cuda', charset=None):
        self.model = model
        self.device = device
        self.model.eval()
        
        # è·å–å­—ç¬¦é›†
        if charset is None:
            # ParseQé»˜è®¤å­—ç¬¦é›†
            chars = string.digits + string.ascii_lowercase
            self.charset = ['[B]', '[E]'] + list(chars) + ['[P]']
        else:
            self.charset = charset
        self.num_classes = len(self.charset)
        
        # æµ‹è¯•æ¨¡å‹è¾“å‡ºå½¢çŠ¶
        dummy_input = torch.randn(1, 3, 32, 128).to(device)
        with torch.no_grad():
            dummy_output = self.model(dummy_input)
            if hasattr(dummy_output, 'logits'):
                self.output_shape = dummy_output.logits.shape
            else:
                self.output_shape = dummy_output.shape
            print(f"æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {self.output_shape}")
        
    def __call__(self, x):
        """
        AutoAttackçš„å‰å‘ä¼ æ’­å‡½æ•°ã€‚
        
        å‚æ•°:
            x: è¾“å…¥å›¾åƒå¼ é‡ï¼Œå½¢çŠ¶ä¸º(batch_size, channels, height, width)
               æœŸæœ›å€¼åœ¨[0, 1]èŒƒå›´å†…
        
        è¿”å›:
            logits: åˆ†ç±»logitsï¼Œå½¢çŠ¶ä¸º(batch_size, num_classes)
        """
        # ç¡®ä¿ä¸ä½¿ç”¨æ¢¯åº¦è®¡ç®—ï¼ˆä½†å…è®¸æ”»å‡»æ—¶çš„æ¢¯åº¦ï¼‰
        if x.device != self.device:
            x = x.to(self.device)
            
        # æ ‡å‡†åŒ–è¾“å…¥åˆ°æ¨¡å‹æœŸæœ›çš„èŒƒå›´ [-1, 1]
        x_normalized = (x - 0.5) / 0.5
        
        # è·å–æ¨¡å‹è¾“å‡º
        output = self.model(x_normalized)
        
        # å¤„ç†ä¸åŒçš„è¾“å‡ºæ ¼å¼
        if hasattr(output, 'logits'):
            logits = output.logits
        else:
            logits = output
            
        # å¯¹æ–‡æœ¬è¯†åˆ«ä»»åŠ¡ï¼Œæˆ‘ä»¬éœ€è¦å°†åºåˆ—è¾“å‡ºè½¬æ¢ä¸ºåˆ†ç±»é—®é¢˜
        # æ–¹æ³•1: ä½¿ç”¨æœ€å¤§æ± åŒ–èšåˆæ‰€æœ‰ä½ç½®çš„é¢„æµ‹
        if len(logits.shape) == 3:  # (batch_size, seq_len, vocab_size)
            # å–æ¯ä¸ªä½ç½®çš„æœ€å¤§ç½®ä¿¡åº¦ï¼Œç„¶ååœ¨åºåˆ—ç»´åº¦ä¸Šå¹³å‡
            logits = torch.max(logits, dim=1)[0]  # (batch_size, vocab_size)
        
        return logits


def load_model_and_data(model_name, checkpoint_path, data_root, dataset_name):
    """åŠ è½½æ¨¡å‹å’Œå‡†å¤‡æ•°æ®é›†ã€‚"""
    
    print(f"åŠ è½½æ¨¡å‹: {model_name}")
    # ä»æ£€æŸ¥ç‚¹åŠ è½½æ¨¡å‹
    model = load_from_checkpoint(checkpoint_path)
    model.eval()
    
    # ç›´æ¥ä»å›¾åƒæ–‡ä»¶å¤¹åŠ è½½æ•°æ®
    print(f"åŠ è½½æ•°æ®é›†: {dataset_name}")
    
    return model, None


def prepare_text_labels(images, model_wrapper, labels_text=None):
    """
    ä¸ºæ–‡æœ¬è¯†åˆ«ä»»åŠ¡å‡†å¤‡æ­£ç¡®çš„æ ‡ç­¾ã€‚
    
    å‚æ•°:
        images: è¾“å…¥å›¾åƒå¼ é‡
        model_wrapper: æ¨¡å‹åŒ…è£…å™¨
        labels_text: å¯é€‰çš„æ–‡æœ¬æ ‡ç­¾åˆ—è¡¨
        
    è¿”å›:
        tensor: æ ‡ç­¾å¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size,)
    """
    batch_size = images.shape[0]
    
    # æ–¹æ³•1: åŸºäºæ¨¡å‹çš„çœŸå®é¢„æµ‹ä½œä¸ºç›®æ ‡æ ‡ç­¾
    with torch.no_grad():
        model_output = model_wrapper(images)
        # ä½¿ç”¨æ¨¡å‹çš„æœ€é«˜ç½®ä¿¡åº¦é¢„æµ‹ä½œä¸ºç›®æ ‡
        predicted_labels = torch.argmax(model_output, dim=1)
    
    print(f"ç”Ÿæˆäº†{batch_size}ä¸ªæ ·æœ¬çš„æ ‡ç­¾ï¼Œå½¢çŠ¶: {predicted_labels.shape}")
    print(f"æ ‡ç­¾èŒƒå›´: {predicted_labels.min().item()} åˆ° {predicted_labels.max().item()}")
    return predicted_labels



def get_user_input():
    """è·å–ç”¨æˆ·è¾“å…¥çš„é…ç½®"""
    print("=" * 60)
    print("        æ–‡æœ¬è¯†åˆ«æ¨¡å‹çš„AutoAttackå¯¹æŠ—æ”»å‡»è¯„ä¼°")
    print("=" * 60)
    
    # å¯ç”¨æ¨¡å‹åˆ—è¡¨
    available_models = {
        '1': ('parseq-tiny', 'è½»é‡çº§æ¨¡å‹ (6Må‚æ•°)'),
        '2': ('parseq', 'æ ‡å‡†æ¨¡å‹ (23Må‚æ•°)'),
        '3': ('abinet', 'ABINetæ¨¡å‹'),
        '4': ('vitstr', 'ViTSTRæ¨¡å‹'),
        '5': ('crnn', 'CRNNæ¨¡å‹'),
        '6': ('trba', 'TRBAæ¨¡å‹')
    }
    
    # å¯ç”¨æ•°æ®é›†
    available_datasets = {
        '1': 'CUTE80',
        '2': 'IIIT5K', 
        '3': 'SVT',
        '4': 'IC13_857',
        '5': 'IC15_1811'
    }
    
    # æ”»å‡»ç±»å‹
    attack_configs = {
        '1': {
            'name': 'æ ‡å‡†æ”»å‡» (Linf, Îµ=8/255)',
            'norm': 'Linf',
            'epsilon': 8.0/255.0,
            'version': 'standard'
        },
        '2': {
            'name': 'è½»é‡æ”»å‡» (Linf, Îµ=4/255)',
            'norm': 'Linf', 
            'epsilon': 4.0/255.0,
            'version': 'custom',
            'attacks': ['apgd-ce', 'fab']
        },
        '3': {
            'name': 'L2æ”»å‡» (L2, Îµ=0.5)',
            'norm': 'L2',
            'epsilon': 0.5,
            'version': 'standard'
        }
    }
    
    print("\nğŸ“¦ é€‰æ‹©è¦è¯„ä¼°çš„æ¨¡å‹:")
    for key, (model_id, desc) in available_models.items():
        print(f"  {key}. {model_id} - {desc}")
    
    while True:
        model_choice = input("\nè¯·é€‰æ‹©æ¨¡å‹ (1-6): ").strip()
        if model_choice in available_models:
            model_name = available_models[model_choice][0]
            break
        print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
    
    print(f"\nâœ… å·²é€‰æ‹©æ¨¡å‹: {model_name}")
    
    print("\nğŸ“Š é€‰æ‹©æµ‹è¯•æ•°æ®é›†:")
    for key, dataset in available_datasets.items():
        print(f"  {key}. {dataset}")
    
    while True:
        dataset_choice = input("\nè¯·é€‰æ‹©æ•°æ®é›† (1-5, é»˜è®¤CUTE80): ").strip()
        if not dataset_choice:
            dataset_name = 'CUTE80'
            break
        elif dataset_choice in available_datasets:
            dataset_name = available_datasets[dataset_choice]
            break
        print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
    
    print(f"âœ… å·²é€‰æ‹©æ•°æ®é›†: {dataset_name}")
    
    print("\nâš”ï¸ é€‰æ‹©æ”»å‡»ç±»å‹:")
    for key, config in attack_configs.items():
        print(f"  {key}. {config['name']}")
    
    while True:
        attack_choice = input("\nè¯·é€‰æ‹©æ”»å‡»ç±»å‹ (1-3, é»˜è®¤1): ").strip()
        if not attack_choice:
            attack_choice = '1'
        if attack_choice in attack_configs:
            attack_config = attack_configs[attack_choice]
            break
        print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
    
    print(f"âœ… å·²é€‰æ‹©æ”»å‡»: {attack_config['name']}")
    
    # æ ·æœ¬æ•°é‡
    while True:
        try:
            n_examples = input("\nğŸ”¢ æµ‹è¯•æ ·æœ¬æ•°é‡ (é»˜è®¤10): ").strip()
            if not n_examples:
                n_examples = 10
            else:
                n_examples = int(n_examples)
            if n_examples > 0:
                break
            print("âŒ æ ·æœ¬æ•°é‡å¿…é¡»å¤§äº0")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
    
    print(f"âœ… æµ‹è¯•æ ·æœ¬æ•°é‡: {n_examples}")
    
    # è®¾å¤‡é€‰æ‹©
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    if torch.cuda.is_available():
        use_cuda = input(f"\nğŸ’» ä½¿ç”¨GPUåŠ é€Ÿ? (y/n, é»˜è®¤y): ").strip().lower()
        if use_cuda in ['n', 'no']:
            device = 'cpu'
    
    print(f"âœ… ä½¿ç”¨è®¾å¤‡: {device}")
      # è‡ªåŠ¨æ£€æµ‹æ•°æ®æ ¹ç›®å½•
    current_script_dir = Path(__file__).parent
    possible_data_roots = [
        '.',  # å½“å‰ç›®å½•
        '../..',  # ä¸Šä¸¤çº§ç›®å½•ï¼ˆé¡¹ç›®æ ¹ç›®å½•ï¼‰
        current_script_dir / '../..',  # ç›¸å¯¹äºè„šæœ¬çš„é¡¹ç›®æ ¹ç›®å½•
        Path(__file__).parent.parent.parent  # ç»å¯¹è·¯å¾„åˆ°é¡¹ç›®æ ¹ç›®å½•
    ]
    
    data_root = '.'
    for root in possible_data_roots:
        test_path = Path(root) / dataset_name
        if test_path.exists():
            data_root = str(root)
            print(f"âœ… æ‰¾åˆ°æ•°æ®é›†è·¯å¾„: {test_path.absolute()}")
            break
    else:
        print(f"âš ï¸ è­¦å‘Š: æ— æ³•è‡ªåŠ¨å®šä½{dataset_name}æ•°æ®é›†ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„")
    
    return {
        'model_name': model_name,
        'checkpoint': f'pretrained={model_name}',
        'dataset': dataset_name,
        'n_examples': n_examples,
        'device': device,
        'data_root': data_root,
        'save_dir': './results/autoattack',
        'batch_size': 4,
        **attack_config
    }


def evaluate_model_wrapper(model_wrapper, images, device):
    """
    è¯„ä¼°æ¨¡å‹åŒ…è£…å™¨çš„æ€§èƒ½ï¼Œç¡®ä¿å®ƒæ­£å¸¸å·¥ä½œã€‚
    
    å‚æ•°:
        model_wrapper: æ¨¡å‹åŒ…è£…å™¨å®ä¾‹
        images: æµ‹è¯•å›¾åƒ
        device: è®¡ç®—è®¾å¤‡
    
    è¿”å›:
        bool: æ˜¯å¦é€šè¿‡åŸºæœ¬æµ‹è¯•
    """
    print("ğŸ” è¯„ä¼°æ¨¡å‹åŒ…è£…å™¨æ€§èƒ½...")
    
    try:
        with torch.no_grad():
            # æµ‹è¯•å‰å‘ä¼ æ’­
            outputs = model_wrapper(images[:2])  # æµ‹è¯•å‰2ä¸ªæ ·æœ¬
            
            print(f"âœ… æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {outputs.shape}")
            print(f"âœ… è¾“å‡ºæ•°å€¼èŒƒå›´: [{outputs.min().item():.4f}, {outputs.max().item():.4f}]")
            print(f"âœ… è¾“å‡ºå‡å€¼: {outputs.mean().item():.4f}")
            print(f"âœ… è¾“å‡ºæ ‡å‡†å·®: {outputs.std().item():.4f}")
            
            # æ£€æŸ¥è¾“å‡ºæ˜¯å¦åˆç†
            if torch.isnan(outputs).any():
                print("âŒ æ¨¡å‹è¾“å‡ºåŒ…å«NaNå€¼")
                return False
            
            if torch.isinf(outputs).any():
                print("âŒ æ¨¡å‹è¾“å‡ºåŒ…å«æ— ç©·å€¼")
                return False
                
            # æ£€æŸ¥è¾“å‡ºæ˜¯å¦æœ‰å˜åŒ–ï¼ˆä¸æ˜¯å…¨é›¶æˆ–å…¨ç›¸åŒï¼‰
            if outputs.std().item() < 1e-6:
                print("âŒ æ¨¡å‹è¾“å‡ºç¼ºä¹å˜åŒ–ï¼ˆå¯èƒ½æ˜¯å…¨é›¶æˆ–å…¨ç›¸åŒï¼‰")
                return False
            
            print("âœ… æ¨¡å‹åŒ…è£…å™¨æµ‹è¯•é€šè¿‡")
            return True
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŒ…è£…å™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    


def main():
    """ä¸»å‡½æ•° - äº¤äº’å¼AutoAttackè¯„ä¼°"""
    try:
        # è·å–ç”¨æˆ·é…ç½®
        config = get_user_input()
        
        print("\nğŸš€ AutoAttackè¯„ä¼°")
        print(f"æ¨¡å‹: {config['model_name']}")
        print(f"æ•°æ®é›†: {config['dataset']}")
        print(f"æ”»å‡»: {config['name']}")
        print(f"æ ·æœ¬æ•°: {config['n_examples']}")
        print("-" * 40)
        
        # è®¾ç½®ä¿å­˜è·¯å¾„
        save_dir = Path(config['save_dir'])
        save_dir.mkdir(parents=True, exist_ok=True)
        log_dir = save_dir / 'logs'
        log_dir.mkdir(parents=True, exist_ok=True)
        config['log_path'] = str(log_dir / f"autoattack_{config['model_name']}_{config['dataset']}.log")
        
        # åˆ›å»ºé…ç½®å¯¹è±¡
        class Config:
            def __init__(self, **kwargs):
                for key, value in kwargs.items():
                    setattr(self, key, value)
        
        args = Config(**config)
        
        # åŠ è½½æ¨¡å‹å’Œæ•°æ®
        model, _ = load_model_and_data(
            args.model_name, args.checkpoint, args.data_root, args.dataset
        )
        device = torch.device(args.device if torch.cuda.is_available() else 'cpu')
        model = model.to(device)
        
        # ä¸ºAutoAttackåˆ›å»ºæ¨¡å‹åŒ…è£…å™¨
        print("ğŸ”§ åˆ›å»ºæ¨¡å‹åŒ…è£…å™¨...")1
        model_wrapper = TextRecognitionModelWrapper(model, device)
          # å‡†å¤‡æµ‹è¯•æ•°æ® - ç›´æ¥ä»å›¾åƒæ–‡ä»¶å¤¹åŠ è½½
        import glob
        from PIL import Image
        from torchvision import transforms
        
        dataset_path = os.path.join(args.data_root, args.dataset)
        print(f"ğŸ” æ­£åœ¨æœç´¢æ•°æ®é›†è·¯å¾„: {dataset_path}")
        print(f"ğŸ“ ç»å¯¹è·¯å¾„: {os.path.abspath(dataset_path)}")
        
        image_files = glob.glob(os.path.join(dataset_path, '*.jpg')) + \
                      glob.glob(os.path.join(dataset_path, '*.JPG')) + \
                      glob.glob(os.path.join(dataset_path, '*.png'))

        if not image_files:
            print(f"âŒ åœ¨{dataset_path}ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶ï¼")
            print(f"ğŸ” è°ƒè¯•ä¿¡æ¯:")
            print(f"   - å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
            print(f"   - è„šæœ¬ä½ç½®: {os.path.dirname(os.path.abspath(__file__))}")
            print(f"   - args.data_root: {args.data_root}")
            print(f"   - args.dataset: {args.dataset}")
            print(f"   - æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨: {os.path.exists(dataset_path)}")
            if os.path.exists(dataset_path):
                print(f"   - ç›®å½•å†…å®¹: {os.listdir(dataset_path)}")
            return
        
        print(f"ğŸ“¸ åŠ è½½{len(image_files)}å¼ å›¾åƒä¸­çš„{args.n_examples}å¼ ...")
        
        # ä½¿ç”¨æ¨¡å‹çš„å›¾åƒå˜æ¢
        img_transform = SceneTextDataModule.get_transform((32, 128))
        
        images_list = []
        labels_list = []
        
        for i, img_path in enumerate(tqdm(image_files[:args.n_examples])):
            # åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ
            image = Image.open(img_path).convert('RGB')
            image_tensor = img_transform(image).unsqueeze(0)
            images_list.append(image_tensor)
            
            # ä½¿ç”¨æ–‡ä»¶åä½œä¸ºä¼ªæ ‡ç­¾ï¼ˆè¿™é‡Œåªæ˜¯ä¸ºäº†æµ‹è¯•ï¼‰
            filename = os.path.basename(img_path).split('.')[0]
            labels_list.append(filename)
        
        if not images_list:
            print("âŒ æœªæ‰¾åˆ°æµ‹è¯•æ•°æ®ï¼")
            return
        
        # è¿æ¥æ‰€æœ‰å›¾åƒ
        images = torch.cat(images_list, dim=0)
        
        # ç§»åŠ¨åˆ°è®¾å¤‡
        images = images.to(device)
        
        # ç¡®ä¿å›¾åƒåœ¨[0,1]èŒƒå›´å†…
        images = torch.clamp(images, 0.0, 1.0)
        
        print(f"âœ… åŠ è½½{len(images)}å¼ å›¾åƒ (èŒƒå›´: {images.min().item():.2f}-{images.max().item():.2f})")
        
        # é¦–å…ˆè¯„ä¼°æ¨¡å‹åŒ…è£…å™¨
        if not evaluate_model_wrapper(model_wrapper, images, device):
            print("âŒ æ¨¡å‹åŒ…è£…å™¨è¯„ä¼°å¤±è´¥ï¼Œåœæ­¢AutoAttack")
            return
        
        # ç”Ÿæˆæ­£ç¡®çš„æ ‡ç­¾
        print("ğŸ·ï¸ ç”Ÿæˆæ ‡ç­¾...")
        labels_for_autoattack = prepare_text_labels(images, model_wrapper, labels_list)
        
        # éªŒè¯æ¨¡å‹åœ¨å¹²å‡€æ ·æœ¬ä¸Šçš„æ€§èƒ½
        print("ğŸ” éªŒè¯æ¨¡å‹æ€§èƒ½...")
        with torch.no_grad():
            clean_outputs = model_wrapper(images)
            clean_predictions = torch.argmax(clean_outputs, dim=1)
            clean_accuracy = (clean_predictions == labels_for_autoattack).float().mean()
            print(f"ğŸ“ˆ å¹²å‡€æ ·æœ¬å‡†ç¡®ç‡: {clean_accuracy.item():.2%}")
            
            if clean_accuracy.item() < 0.01:  # å¦‚æœå‡†ç¡®ç‡å¤ªä½
                print("âš ï¸ è­¦å‘Š: å¹²å‡€æ ·æœ¬å‡†ç¡®ç‡å¾ˆä½ï¼Œå¯èƒ½å­˜åœ¨æ¨¡å‹æˆ–æ•°æ®é—®é¢˜")
                print("ğŸ’¡ å°è¯•ä½¿ç”¨ä¸åŒçš„æ ‡ç­¾ç­–ç•¥...")
                # ä½¿ç”¨æ¨¡å‹çš„top-1é¢„æµ‹ä½œä¸º"çœŸå®"æ ‡ç­¾
                labels_for_autoattack = clean_predictions.clone()
                print(f"ğŸ”„ ä½¿ç”¨æ¨¡å‹é¢„æµ‹ä½œä¸ºç›®æ ‡æ ‡ç­¾: {labels_for_autoattack[:5]}")
        
        # è¿è¡ŒAutoAttackè¯„ä¼°
        print(f"\nğŸš€ è¿è¡ŒAutoAttack (norm={args.norm}, Îµ={args.epsilon:.4f})...")
        
        # åˆå§‹åŒ–AutoAttack (å…³é—­è¯¦ç»†è¾“å‡º)
        adversary = AutoAttack(
            model_wrapper, 
            norm=args.norm, 
            eps=args.epsilon,
            version=args.version,
            verbose=False  # å…³é—­è¯¦ç»†è¾“å‡º
        )
        
        # å¦‚æœæŒ‡å®šäº†è‡ªå®šä¹‰æ”»å‡»ï¼Œåˆ™é…ç½®è‡ªå®šä¹‰æ”»å‡»
        if args.version == 'custom' and hasattr(args, 'attacks'):
            adversary.attacks_to_run = args.attacks
            print(f"   æ”»å‡»åºåˆ—: {args.attacks}")
        
        # è¿è¡ŒAutoAttack - ä¸ä½¿ç”¨torch.no_grad()ï¼Œå› ä¸ºæ”»å‡»éœ€è¦æ¢¯åº¦
        adv_complete = adversary.run_standard_evaluation(
            images, labels_for_autoattack, bs=args.batch_size
        )
        
        # ä¿å­˜ç»“æœ
        save_dir = Path(args.save_dir)
        save_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¡ç®—æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š æ”»å‡»ç»“æœ:")
        
        # è®¡ç®—æ‰°åŠ¨ç»Ÿè®¡
        if adv_complete is not None and len(adv_complete) > 0:
            perturbation = adv_complete - images
            if args.norm == 'Linf':
                max_pert = torch.norm(perturbation.view(perturbation.shape[0], -1), p=float('inf'), dim=1).max()
                avg_pert = torch.norm(perturbation.view(perturbation.shape[0], -1), p=float('inf'), dim=1).mean()
            else:
                max_pert = torch.norm(perturbation.view(perturbation.shape[0], -1), p=2, dim=1).max()
                avg_pert = torch.norm(perturbation.view(perturbation.shape[0], -1), p=2, dim=1).mean()
            
            # éªŒè¯å¯¹æŠ—æ ·æœ¬çš„æ•ˆæœ
            with torch.no_grad():
                adv_outputs = model_wrapper(adv_complete)
                adv_predictions = torch.argmax(adv_outputs, dim=1)
                robust_accuracy = (adv_predictions == labels_for_autoattack).float().mean()
                
            print(f"   å¹²å‡€å‡†ç¡®ç‡:     {clean_accuracy.item():.1%}")
            print(f"   é²æ£’å‡†ç¡®ç‡:     {robust_accuracy.item():.1%}")
            print(f"   æ”»å‡»æˆåŠŸç‡:     {(1 - robust_accuracy.item()):.1%}")
            print(f"   æœ€å¤§æ‰°åŠ¨:       {max_pert:.4f}")
            print(f"   å¹³å‡æ‰°åŠ¨:       {avg_pert:.4f}")
            print(f"   æ‰°åŠ¨é¢„ç®—:       {args.epsilon:.4f}")
        
        # ç”Ÿæˆæ–‡ä»¶å
        filename = f"autoattack_{args.version}_{args.model_name}_{args.dataset}_n{len(adv_complete)}_eps{args.epsilon:.4f}.pth"
        save_path = save_dir / filename
        
        # ä¿å­˜ç»“æœ
        save_dict = {
            'adversarial_examples': adv_complete,
            'original_images': images,
            'labels': labels_for_autoattack,
            'config': config,
            'model_name': args.model_name,
            'dataset_name': args.dataset,
            'epsilon': args.epsilon,
            'norm': args.norm,
            'version': args.version
        }
        
        if 'max_pert' in locals():
            save_dict.update({
                'max_perturbation': max_pert.item(),
                'avg_perturbation': avg_pert.item(),
                'robust_accuracy': robust_accuracy.item(),
                'attack_success_rate': 1 - robust_accuracy.item()
            })
        
        torch.save(save_dict, save_path)
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {save_path}")
        print("âœ… AutoAttackå®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\nâŒ ç”¨æˆ·ä¸­æ–­äº†è¯„ä¼°è¿‡ç¨‹")
    except Exception as e:
        print(f"âŒ AutoAttackè¯„ä¼°è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
if __name__ == '__main__':
    main()
