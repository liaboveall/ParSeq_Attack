{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09aaec0e",
   "metadata": {},
   "source": [
    "# PARSeq 文本识别模型对抗攻击实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e538338",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:28:32.835134Z",
     "start_time": "2025-06-06T17:28:32.826336Z"
    }
   },
   "outputs": [],
   "source": [
    "# 导入所需的库\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "# 添加父目录到Python路径以便导入strhub模块\n",
    "sys.path.append(str(Path(__file__).parent.parent) if '__file__' in globals() else str(Path.cwd().parent))\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置图片显示\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"导入库完成！\")\n",
    "print(f\"PyTorch版本: {torch.__version__}\")\n",
    "print(f\"设备: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a37ba9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:28:32.869330Z",
     "start_time": "2025-06-06T17:28:32.865386Z"
    }
   },
   "outputs": [],
   "source": [
    "# 正确的文本识别解码方法\n",
    "def predict_text(model, images):\n",
    "    \"\"\"使用模型的tokenizer正确解码文本\"\"\"\n",
    "    with torch.no_grad():\n",
    "        # 获取模型输出的概率分布\n",
    "        logits = model(images)\n",
    "        probs = logits.softmax(-1)\n",
    "        \n",
    "        # 使用模型自带的tokenizer解码\n",
    "        predictions, confidences = model.tokenizer.decode(probs)\n",
    "        \n",
    "    return predictions\n",
    "\n",
    "print(\"文本识别函数准备完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a822b6f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:28:33.107840Z",
     "start_time": "2025-06-06T17:28:33.101034Z"
    }
   },
   "outputs": [],
   "source": [
    "# 模型选择配置\n",
    "\"\"\"\n",
    "PARSeq模型选择器 - 支持所有可用的预训练模型\n",
    "\"\"\"\n",
    "\n",
    "# 定义所有可用的PARSeq模型\n",
    "AVAILABLE_MODELS = {\n",
    "    1: {\n",
    "        'name': 'parseq_tiny', \n",
    "        'description': '微型模型 - 最快速度，适合快速测试',\n",
    "        'params': '~1M',\n",
    "        'accuracy': '中等'\n",
    "    },\n",
    "    2: {\n",
    "        'name': 'parseq_patch16_224', \n",
    "        'description': '标准模型 - 平衡性能和速度',\n",
    "        'params': '~23M',\n",
    "        'accuracy': '高'\n",
    "    },\n",
    "    3: {\n",
    "        'name': 'parseq', \n",
    "        'description': '完整模型 - 最佳性能',\n",
    "        'params': '~23M',\n",
    "        'accuracy': '最高'\n",
    "    },\n",
    "    4: {\n",
    "        'name': 'parseq_base', \n",
    "        'description': '基础模型 - 标准配置',\n",
    "        'params': '~23M',\n",
    "        'accuracy': '高'\n",
    "    }\n",
    "}\n",
    "\n",
    "def display_model_options():\n",
    "    \"\"\"显示所有可用的模型选项\"\"\"\n",
    "    print(\"可用的PARSeq模型:\")\n",
    "    print(\"=\" * 80)\n",
    "    for idx, model_info in AVAILABLE_MODELS.items():\n",
    "        print(f\"{idx}. {model_info['name']}\")\n",
    "        print(f\"   描述: {model_info['description']}\")\n",
    "        print(f\"   参数量: {model_info['params']}\")\n",
    "        print(f\"   准确性: {model_info['accuracy']}\")\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "def select_model():\n",
    "    \"\"\"交互式模型选择\"\"\"\n",
    "    display_model_options()\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            choice = input(\"\\n请选择模型 (输入数字 1-4): \").strip()\n",
    "            choice = int(choice)\n",
    "            \n",
    "            if choice in AVAILABLE_MODELS:\n",
    "                selected_model = AVAILABLE_MODELS[choice]\n",
    "                print(f\"\\n已选择: {selected_model['name']}\")\n",
    "                print(f\"{selected_model['description']}\")\n",
    "                return selected_model['name']\n",
    "            else:\n",
    "                print(\"无效选择，请输入 1-4 之间的数字\")\n",
    "                \n",
    "        except ValueError:\n",
    "            print(\"请输入有效的数字\")\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\n用户取消选择，使用默认模型: parseq\")\n",
    "            return 'parseq'\n",
    "\n",
    "# 选择模型 (您可以修改这里来直接指定模型)\n",
    "# 方式1: 交互式选择 (取消注释下面这行)\n",
    "# selected_model_name = select_model()\n",
    "\n",
    "# 方式2: 直接指定模型 (推荐在notebook中使用)\n",
    "selected_model_name = 'parseq'  # 可以改为: 'parseq_tiny', 'parseq_patch16_224', 'parseq_base'\n",
    "\n",
    "print(f\"\\n当前选择的模型: {selected_model_name}\")\n",
    "\n",
    "# 查找选中模型的详细信息\n",
    "selected_info = None\n",
    "for info in AVAILABLE_MODELS.values():\n",
    "    if info['name'] == selected_model_name:\n",
    "        selected_info = info\n",
    "        break\n",
    "\n",
    "if selected_info:\n",
    "    print(f\"模型信息: {selected_info['description']}\")\n",
    "    print(f\"参数量: {selected_info['params']}\")\n",
    "    print(f\"准确性: {selected_info['accuracy']}\")\n",
    "else:\n",
    "    print(\"使用自定义模型名称\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ab1418",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:28:35.113754Z",
     "start_time": "2025-06-06T17:28:33.108921Z"
    }
   },
   "outputs": [],
   "source": [
    "# 加载选择的PARSeq模型\n",
    "print(f\"正在加载PARSeq模型: {selected_model_name}...\")\n",
    "\n",
    "try:\n",
    "    # 动态加载选择的预训练模型\n",
    "    print(f\"从torch.hub加载模型: {selected_model_name}\")\n",
    "    model = torch.hub.load('baudm/parseq', selected_model_name, pretrained=True, trust_repo=True)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    print(f\"{selected_model_name} 模型加载成功!\")\n",
    "    \n",
    "    # 获取模型信息\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"模型统计信息:\")\n",
    "    print(f\"   总参数量: {total_params:,}\")\n",
    "    print(f\"   可训练参数: {trainable_params:,}\")\n",
    "    print(f\"   模型大小: ~{total_params * 4 / 1024 / 1024:.1f} MB\")\n",
    "    \n",
    "    # 测试模型\n",
    "    print(f\"测试模型...\")\n",
    "    dummy_input = torch.randn(1, 3, 32, 128).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(dummy_input)\n",
    "    print(f\"模型测试通过，输出形状: {output.shape}\")\n",
    "    \n",
    "    # 显示模型架构概要\n",
    "    print(f\"\\n模型架构:\")\n",
    "    print(f\"   输入尺寸: {model.hparams.img_size}\")\n",
    "    print(f\"   最大序列长度: {model.hparams.max_label_length}\")\n",
    "    if hasattr(model.hparams, 'charset_size'):\n",
    "        print(f\"   字符集大小: {model.hparams.charset_size}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"模型 {selected_model_name} 加载失败: {e}\")\n",
    "    print(\"尝试加载备用模型 parseq...\")\n",
    "    try:\n",
    "        model = torch.hub.load('baudm/parseq', 'parseq', pretrained=True, trust_repo=True)\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        selected_model_name = 'parseq'\n",
    "        print(\"备用模型加载成功!\")\n",
    "    except Exception as e2:\n",
    "        print(f\"备用模型也加载失败: {e2}\")\n",
    "        raise\n",
    "\n",
    "# 加载CUTE80数据集的前三张图像\n",
    "cute80_dir = Path(\"../CUTE80\")\n",
    "print(f\"\\nCUTE80数据集路径: {cute80_dir.absolute()}\")\n",
    "\n",
    "# 获取图像文件列表\n",
    "image_files = []\n",
    "for ext in ['*.jpg', '*.JPG', '*.png', '*.PNG']:\n",
    "    image_files.extend(list(cute80_dir.glob(ext)))\n",
    "\n",
    "if len(image_files) == 0:\n",
    "    print(\"未找到图像文件！请检查CUTE80数据集路径\")\n",
    "else:\n",
    "    print(f\"找到 {len(image_files)} 张图像\")\n",
    "    \n",
    "# 选择前3张图像进行演示\n",
    "test_images = image_files[:3]\n",
    "print(\"选择用于演示的图像:\")\n",
    "for i, img_path in enumerate(test_images):\n",
    "    print(f\"  {i+1}. {img_path.name}\")\n",
    "\n",
    "print(f\"\\n当前使用模型: {selected_model_name}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4e34b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:28:35.119643Z",
     "start_time": "2025-06-06T17:28:35.114395Z"
    }
   },
   "outputs": [],
   "source": [
    "# 快速模型切换 (可选)\n",
    "\"\"\"\n",
    "如果您想要切换到其他模型，请修改下面的模型名称并运行此cell\n",
    "然后重新运行后续的实验cell\n",
    "\"\"\"\n",
    "\n",
    "def switch_model(new_model_name):\n",
    "    \"\"\"快速切换模型\"\"\"\n",
    "    global model, selected_model_name\n",
    "    \n",
    "    print(f\"切换到模型: {new_model_name}\")\n",
    "    \n",
    "    try:\n",
    "        # 释放当前模型内存\n",
    "        if 'model' in globals():\n",
    "            del model\n",
    "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "        \n",
    "        # 加载新模型\n",
    "        model = torch.hub.load('baudm/parseq', new_model_name, pretrained=True, trust_repo=True)\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        selected_model_name = new_model_name\n",
    "        \n",
    "        # 显示模型信息\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        print(f\"成功切换到 {new_model_name}\")\n",
    "        print(f\"参数量: {total_params:,}\")\n",
    "        print(f\"模型大小: ~{total_params * 4 / 1024 / 1024:.1f} MB\")\n",
    "        \n",
    "        # 测试模型\n",
    "        dummy_input = torch.randn(1, 3, 32, 128).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(dummy_input)\n",
    "        print(f\"模型测试通过\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"模型切换失败: {e}\")\n",
    "        return False\n",
    "\n",
    "# 使用示例:\n",
    "# 取消注释下面任意一行来切换模型:\n",
    "\n",
    "# switch_model('parseq_tiny')        # 切换到微型模型\n",
    "# switch_model('parseq')             # 切换到完整模型  \n",
    "# switch_model('parseq_patch16_224') # 切换到patch16模型\n",
    "# switch_model('parseq_base')        # 切换到基础模型\n",
    "\n",
    "print(\"模型切换功能已准备就绪\")\n",
    "print(\"如需切换模型，请取消注释上面的任意一行\")\n",
    "print(f\"当前使用模型: {selected_model_name}\")\n",
    "\n",
    "# 显示所有可用模型的快捷切换命令\n",
    "print(\"\\n可用的模型切换命令:\")\n",
    "for idx, model_info in AVAILABLE_MODELS.items():\n",
    "    print(f\"   switch_model('{model_info['name']}')  # {model_info['description']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40932a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:28:35.139911Z",
     "start_time": "2025-06-06T17:28:35.120266Z"
    }
   },
   "outputs": [],
   "source": [
    "# 加载CUTE80数据集的前三张图像\n",
    "cute80_dir = Path(\"../CUTE80\")\n",
    "print(f\"CUTE80数据集路径: {cute80_dir}\")\n",
    "\n",
    "# 查找图像文件，避免重复\n",
    "image_files = []\n",
    "for ext in ['*.png', '*.jpg', '*.jpeg', '*.PNG', '*.JPG', '*.JPEG']:\n",
    "    image_files.extend(list(cute80_dir.glob(ext)))\n",
    "\n",
    "# 去除重复文件（Windows文件系统中.jpg和.JPG可能指向同一文件）\n",
    "unique_files = {}\n",
    "for file_path in image_files:\n",
    "    # 使用文件的绝对路径作为唯一标识符\n",
    "    key = str(file_path.resolve()).lower()\n",
    "    if key not in unique_files:\n",
    "        unique_files[key] = file_path\n",
    "\n",
    "image_files = sorted(unique_files.values())[:3]  # 取前三张图像\n",
    "print(f\"找到 {len(image_files)} 张图像\")\n",
    "\n",
    "# 显示选中的图像文件\n",
    "for i, img_path in enumerate(image_files):\n",
    "    print(f\"  {i+1}. {img_path.name}\")\n",
    "\n",
    "# 使用与read.py相同的图像预处理方法\n",
    "from strhub.data.module import SceneTextDataModule\n",
    "transform = SceneTextDataModule.get_transform(model.hparams.img_size)\n",
    "\n",
    "# 加载图像\n",
    "original_images = []\n",
    "image_tensors = []\n",
    "image_names = []\n",
    "\n",
    "print(\"\\n加载图像...\")\n",
    "for i, img_path in enumerate(image_files):\n",
    "    # 加载原始图像\n",
    "    orig_img = Image.open(img_path).convert('RGB')\n",
    "    original_images.append(orig_img)\n",
    "    \n",
    "    # 预处理\n",
    "    img_tensor = transform(orig_img)\n",
    "    image_tensors.append(img_tensor)\n",
    "    \n",
    "    # 获取真实标签（从文件名）\n",
    "    true_label = img_path.stem  # 使用文件名作为真实标签\n",
    "    image_names.append(true_label)\n",
    "    \n",
    "    print(f\"  图像 {i+1}: {img_path.name} -> {orig_img.size}\")\n",
    "\n",
    "# 转换为batch\n",
    "images_batch = torch.stack(image_tensors).to(device)\n",
    "print(f\"\\n图像批次准备完成，形状: {images_batch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e2c3b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:28:35.380996Z",
     "start_time": "2025-06-06T17:28:35.139911Z"
    }
   },
   "outputs": [],
   "source": [
    "# 对原始图像进行正确的文本识别\n",
    "print(\"对原始图像进行文本识别...\")\n",
    "\n",
    "# 使用正确的识别方法\n",
    "original_texts = predict_text(model, images_batch)\n",
    "\n",
    "print(\"原始图像识别完成!\")\n",
    "print(\"\\n正确的识别结果:\")\n",
    "for i, (name, text) in enumerate(zip(image_names, original_texts)):\n",
    "    print(f\"  图像 {i+1} ({name}): \\\"{text}\\\"\")\n",
    "\n",
    "# 可视化原始图像和识别结果\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "fig.suptitle(\"Original Images and Recognition Results\", fontsize=16, fontweight='bold')\n",
    "\n",
    "for i in range(3):\n",
    "    # 显示原始图像\n",
    "    axes[i].imshow(original_images[i])\n",
    "    axes[i].set_title(f'Image {i+1}\\nRecognition: \"{original_texts[i]}\"', \n",
    "                     fontsize=12, pad=10)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefa4514",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:28:35.389427Z",
     "start_time": "2025-06-06T17:28:35.380996Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义正确的对抗攻击方法\n",
    "class AdversarialAttacker:\n",
    "    \"\"\"对抗攻击器 - 使用正确的模型接口\"\"\"\n",
    "    \n",
    "    def __init__(self, model, device='cpu'):\n",
    "        self.model = model.eval()\n",
    "        self.device = device\n",
    "        \n",
    "    def fgsm_attack(self, images, epsilon=0.1):\n",
    "        \"\"\"\n",
    "        快速梯度符号方法 (FGSM) 攻击\n",
    "        \"\"\"\n",
    "        images = images.clone().detach().to(self.device)\n",
    "        images.requires_grad = True\n",
    "        \n",
    "        # 获取原始预测作为攻击目标\n",
    "        with torch.no_grad():\n",
    "            original_logits = self.model(images)\n",
    "            original_probs = original_logits.softmax(-1)\n",
    "            original_preds, _ = self.model.tokenizer.decode(original_probs)\n",
    "        \n",
    "        # 前向传播获取logits\n",
    "        logits = self.model(images)\n",
    "        probs = logits.softmax(-1)\n",
    "        \n",
    "        # 使用negative log likelihood作为损失 - 最大化损失来产生错误预测\n",
    "        # 这里我们使用一个简化的方法：让模型对当前最可能的预测产生最大的损失\n",
    "        target_indices = logits.argmax(-1)  # 当前最可能的预测\n",
    "        \n",
    "        # 计算交叉熵损失\n",
    "        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), \n",
    "                              target_indices.view(-1))\n",
    "        \n",
    "        # 反向传播\n",
    "        self.model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # 生成对抗样本\n",
    "        data_grad = images.grad.data\n",
    "        sign_data_grad = data_grad.sign()\n",
    "        perturbed_images = images + epsilon * sign_data_grad\n",
    "        \n",
    "        # 限制像素值范围\n",
    "        perturbed_images = torch.clamp(perturbed_images, 0, 1)\n",
    "        \n",
    "        return perturbed_images.detach()\n",
    "    \n",
    "    def pgd_attack(self, images, epsilon=0.1, alpha=0.01, iters=10):\n",
    "        \"\"\"\n",
    "        投影梯度下降 (PGD) 攻击\n",
    "        \"\"\"\n",
    "        images = images.clone().detach().to(self.device)\n",
    "        ori_images = images.clone().detach()\n",
    "        \n",
    "        # 随机初始化扰动\n",
    "        perturbed_images = images + torch.empty_like(images).uniform_(-epsilon, epsilon)\n",
    "        perturbed_images = torch.clamp(perturbed_images, 0, 1)\n",
    "        \n",
    "        for i in range(iters):\n",
    "            perturbed_images.requires_grad = True\n",
    "            \n",
    "            logits = self.model(perturbed_images)\n",
    "            target_indices = logits.argmax(-1)\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), \n",
    "                                  target_indices.view(-1))\n",
    "            \n",
    "            self.model.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            data_grad = perturbed_images.grad.data\n",
    "            sign_data_grad = data_grad.sign()\n",
    "            perturbed_images = perturbed_images.detach() + alpha * sign_data_grad\n",
    "            \n",
    "            # 投影到epsilon球内\n",
    "            delta = torch.clamp(perturbed_images - ori_images, min=-epsilon, max=epsilon)\n",
    "            perturbed_images = torch.clamp(ori_images + delta, 0, 1)\n",
    "            \n",
    "        return perturbed_images.detach()\n",
    "\n",
    "# 创建修正后的攻击器\n",
    "attacker = AdversarialAttacker(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c6f1c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:28:35.444776Z",
     "start_time": "2025-06-06T17:28:35.389427Z"
    }
   },
   "outputs": [],
   "source": [
    "# 执行FGSM攻击\n",
    "print(\"执行FGSM攻击...\")\n",
    "\n",
    "# 设置攻击参数\n",
    "epsilon = 0.1  # 扰动强度\n",
    "\n",
    "# 执行FGSM攻击\n",
    "fgsm_adversarial = attacker.fgsm_attack(images_batch, epsilon=epsilon)\n",
    "\n",
    "print(f\"FGSM攻击完成! (epsilon={epsilon})\")\n",
    "print(f\"   原始图像范围: [{images_batch.min():.3f}, {images_batch.max():.3f}]\")\n",
    "print(f\"   对抗样本范围: [{fgsm_adversarial.min():.3f}, {fgsm_adversarial.max():.3f}]\")\n",
    "\n",
    "# 计算扰动\n",
    "fgsm_perturbation = fgsm_adversarial - images_batch\n",
    "print(f\"   扰动范围: [{fgsm_perturbation.min():.3f}, {fgsm_perturbation.max():.3f}]\")\n",
    "print(f\"   平均扰动幅度: {fgsm_perturbation.abs().mean():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ead4911",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:28:35.467013Z",
     "start_time": "2025-06-06T17:28:35.444776Z"
    }
   },
   "outputs": [],
   "source": [
    "# 对攻击后的图像进行正确的文本识别\n",
    "print(\"对FGSM攻击后的图像进行文本识别...\")\n",
    "\n",
    "# 使用正确的识别方法\n",
    "fgsm_texts = predict_text(model, fgsm_adversarial)\n",
    "\n",
    "print(\"FGSM对抗样本识别完成!\")\n",
    "\n",
    "# 比较攻击前后的结果\n",
    "print(\"\\nFGSM攻击效果对比:\")\n",
    "print(\"=\"*60)\n",
    "for i in range(3):\n",
    "    attack_success = original_texts[i] != fgsm_texts[i]\n",
    "    status = \"[攻击成功]\" if attack_success else \"[攻击失败]\"\n",
    "    \n",
    "    print(f\"图像 {i+1} ({image_names[i]}):\")\n",
    "    print(f\"  原始识别: \\\"{original_texts[i]}\\\"\")\n",
    "    print(f\"  攻击后:   \\\"{fgsm_texts[i]}\\\"\")\n",
    "    print(f\"  状态:     {status}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# 计算攻击成功率\n",
    "success_count = sum(1 for orig, adv in zip(original_texts, fgsm_texts) if orig != adv)\n",
    "success_rate = success_count / len(original_texts)\n",
    "print(f\"\\nFGSM攻击成功率: {success_count}/{len(original_texts)} = {success_rate:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e2c16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:28:35.802379Z",
     "start_time": "2025-06-06T17:28:35.467013Z"
    }
   },
   "outputs": [],
   "source": [
    "# 执行PGD攻击进行对比\n",
    "print(\"执行PGD攻击...\")\n",
    "\n",
    "# PGD攻击参数\n",
    "pgd_epsilon = 0.1\n",
    "pgd_alpha = 0.02\n",
    "pgd_iters = 10\n",
    "\n",
    "# 执行PGD攻击\n",
    "pgd_adversarial = attacker.pgd_attack(images_batch, \n",
    "                                     epsilon=pgd_epsilon, \n",
    "                                     alpha=pgd_alpha, \n",
    "                                     iters=pgd_iters)\n",
    "\n",
    "print(f\"PGD攻击完成! (epsilon={pgd_epsilon}, alpha={pgd_alpha}, iters={pgd_iters})\")\n",
    "\n",
    "# 对PGD对抗样本进行正确识别\n",
    "pgd_texts = predict_text(model, pgd_adversarial)\n",
    "\n",
    "print(\"PGD对抗样本识别完成!\")\n",
    "\n",
    "# PGD攻击效果\n",
    "print(\"\\nPGD攻击效果对比:\")\n",
    "print(\"=\"*60)\n",
    "for i in range(3):\n",
    "    attack_success = original_texts[i] != pgd_texts[i]\n",
    "    status = \"[攻击成功]\" if attack_success else \"[攻击失败]\"\n",
    "    \n",
    "    print(f\"图像 {i+1} ({image_names[i]}):\")\n",
    "    print(f\"  原始识别: \\\"{original_texts[i]}\\\"\")\n",
    "    print(f\"  PGD攻击后: \\\"{pgd_texts[i]}\\\"\")\n",
    "    print(f\"  状态:     {status}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# 计算PGD攻击成功率\n",
    "pgd_success_count = sum(1 for orig, adv in zip(original_texts, pgd_texts) if orig != adv)\n",
    "pgd_success_rate = pgd_success_count / len(original_texts)\n",
    "print(f\"\\nPGD攻击成功率: {pgd_success_count}/{len(original_texts)} = {pgd_success_rate:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4772ae58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:28:35.807447Z",
     "start_time": "2025-06-06T17:28:35.803157Z"
    }
   },
   "outputs": [],
   "source": [
    "# 反归一化函数用于可视化\n",
    "def denormalize_tensor(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
    "    \"\"\"将归一化的tensor转换回[0,1]范围用于显示\"\"\"\n",
    "    mean = torch.tensor(mean).view(1, 3, 1, 1).to(tensor.device)\n",
    "    std = torch.tensor(std).view(1, 3, 1, 1).to(tensor.device)\n",
    "    \n",
    "    # 反归一化\n",
    "    denorm = tensor * std + mean\n",
    "    \n",
    "    # 限制到[0,1]范围\n",
    "    denorm = torch.clamp(denorm, 0, 1)\n",
    "    \n",
    "    return denorm\n",
    "\n",
    "def tensor_to_image(tensor):\n",
    "    \"\"\"将tensor转换为可显示的numpy数组\"\"\"\n",
    "    if tensor.dim() == 4:  # batch tensor\n",
    "        tensor = tensor[0]  # 取第一张图\n",
    "    \n",
    "    # 转换维度顺序: CHW -> HWC\n",
    "    img = tensor.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    # 确保在[0,1]范围内\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    return img\n",
    "\n",
    "print(\"Visualization helper functions ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68924a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:28:36.243696Z",
     "start_time": "2025-06-06T17:28:35.807447Z"
    }
   },
   "outputs": [],
   "source": [
    "# 可视化攻击效果对比\n",
    "print(\"Generating visualization comparison...\")\n",
    "\n",
    "# 首先以文本形式输出攻击结果\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"文本识别攻击结果对比\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i in range(len(original_texts)):\n",
    "    print(f\"\\n图像 {i+1} ({image_names[i]}):\")\n",
    "    print(f\"   原始识别结果: \\\"{original_texts[i]}\\\"\")\n",
    "    \n",
    "    # FGSM攻击结果\n",
    "    fgsm_status = \"[攻击成功]\" if original_texts[i] != fgsm_texts[i] else \"[攻击失败]\"\n",
    "    print(f\"   FGSM攻击后: \\\"{fgsm_texts[i]}\\\" {fgsm_status}\")\n",
    "    \n",
    "    # PGD攻击结果\n",
    "    pgd_status = \"[攻击成功]\" if original_texts[i] != pgd_texts[i] else \"[攻击失败]\"\n",
    "    print(f\"   PGD攻击后:  \\\"{pgd_texts[i]}\\\" {pgd_status}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"攻击统计:\")\n",
    "print(f\"   FGSM成功率: {success_rate:.1%} ({success_count}/{len(original_texts)})\")\n",
    "print(f\"   PGD成功率:  {pgd_success_rate:.1%} ({pgd_success_count}/{len(original_texts)})\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# 反归一化用于显示\n",
    "original_denorm = denormalize_tensor(images_batch)\n",
    "fgsm_denorm = denormalize_tensor(fgsm_adversarial)\n",
    "pgd_denorm = denormalize_tensor(pgd_adversarial)\n",
    "\n",
    "# 计算扰动\n",
    "fgsm_perturbation = fgsm_denorm - original_denorm\n",
    "pgd_perturbation = pgd_denorm - original_denorm\n",
    "\n",
    "# 创建大图进行对比展示\n",
    "fig, axes = plt.subplots(3, 5, figsize=(20, 12))\n",
    "fig.suptitle('PARSeq Text Recognition Model Adversarial Attack Comparison', fontsize=18, fontweight='bold', y=0.98)\n",
    "\n",
    "# 设置列标题\n",
    "col_titles = ['Original Image', 'FGSM Adversarial', 'FGSM Perturbation', 'PGD Adversarial', 'PGD Perturbation']\n",
    "for j, title in enumerate(col_titles):\n",
    "    axes[0, j].set_title(title, fontsize=14, fontweight='bold', pad=15)\n",
    "\n",
    "for i in range(3):  # 三张图像\n",
    "    # 原始图像\n",
    "    axes[i, 0].imshow(tensor_to_image(original_denorm[i]))\n",
    "    axes[i, 0].text(0.5, -0.15, f'Recognition: \"{original_texts[i]}\"', \n",
    "                    transform=axes[i, 0].transAxes, ha='center', fontsize=10,\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\"))\n",
    "    \n",
    "    # FGSM对抗样本\n",
    "    axes[i, 1].imshow(tensor_to_image(fgsm_denorm[i]))\n",
    "    fgsm_success = \"[SUCCESS]\" if original_texts[i] != fgsm_texts[i] else \"[FAILED]\"\n",
    "    axes[i, 1].text(0.5, -0.15, f'Recognition: \"{fgsm_texts[i]}\" {fgsm_success}', \n",
    "                    transform=axes[i, 1].transAxes, ha='center', fontsize=10,\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.3\", \n",
    "                             facecolor=\"lightcoral\" if fgsm_success==\"[SUCCESS]\" else \"lightgray\"))\n",
    "    \n",
    "    # FGSM扰动可视化\n",
    "    pert_img = fgsm_perturbation[i].cpu().permute(1, 2, 0).numpy()\n",
    "    pert_img = (pert_img - pert_img.min()) / (pert_img.max() - pert_img.min() + 1e-8)\n",
    "    axes[i, 2].imshow(pert_img, cmap='seismic')\n",
    "    axes[i, 2].text(0.5, -0.15, f'Magnitude: {fgsm_perturbation[i].abs().mean():.4f}', \n",
    "                    transform=axes[i, 2].transAxes, ha='center', fontsize=10)\n",
    "    \n",
    "    # PGD对抗样本\n",
    "    axes[i, 3].imshow(tensor_to_image(pgd_denorm[i]))\n",
    "    pgd_success = \"[SUCCESS]\" if original_texts[i] != pgd_texts[i] else \"[FAILED]\"\n",
    "    axes[i, 3].text(0.5, -0.15, f'Recognition: \"{pgd_texts[i]}\" {pgd_success}', \n",
    "                    transform=axes[i, 3].transAxes, ha='center', fontsize=10,\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.3\", \n",
    "                             facecolor=\"lightcoral\" if pgd_success==\"[SUCCESS]\" else \"lightgray\"))\n",
    "    \n",
    "    # PGD扰动可视化\n",
    "    pert_img = pgd_perturbation[i].cpu().permute(1, 2, 0).numpy()\n",
    "    pert_img = (pert_img - pert_img.min()) / (pert_img.max() - pert_img.min() + 1e-8)\n",
    "    axes[i, 4].imshow(pert_img, cmap='seismic')\n",
    "    axes[i, 4].text(0.5, -0.15, f'Magnitude: {pgd_perturbation[i].abs().mean():.4f}', \n",
    "                    transform=axes[i, 4].transAxes, ha='center', fontsize=10)\n",
    "    \n",
    "    # 设置行标题\n",
    "    axes[i, 0].text(-0.15, 0.5, f'Image {i+1}\\n({image_names[i]})', \n",
    "                    transform=axes[i, 0].transAxes, ha='center', va='center',\n",
    "                    rotation=90, fontsize=12, fontweight='bold')\n",
    "\n",
    "# 移除所有坐标轴\n",
    "for i in range(3):\n",
    "    for j in range(5):\n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.93, hspace=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualization completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd3004b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:28:36.249379Z",
     "start_time": "2025-06-06T17:28:36.243696Z"
    }
   },
   "outputs": [],
   "source": [
    "# 实验总结\n",
    "\"\"\"\n",
    "PARSeq文本识别模型对抗攻击实验总结\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"实验总结报告\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"使用模型: {selected_model_name}\")\n",
    "print(f\"测试图像数量: {len(original_texts)}\")\n",
    "print(f\"攻击方法: FGSM 和 PGD\")\n",
    "\n",
    "print(f\"\\n攻击结果:\")\n",
    "print(f\"  FGSM攻击成功率: {success_rate:.1%} ({success_count}/{len(original_texts)})\")\n",
    "print(f\"  PGD攻击成功率:  {pgd_success_rate:.1%} ({pgd_success_count}/{len(original_texts)})\")\n",
    "\n",
    "print(f\"\\n攻击参数:\")\n",
    "print(f\"  FGSM epsilon: {epsilon}\")\n",
    "print(f\"  PGD epsilon: {pgd_epsilon}, alpha: {pgd_alpha}, iterations: {pgd_iters}\")\n",
    "\n",
    "print(f\"\\n扰动分析:\")\n",
    "fgsm_avg_perturbation = fgsm_perturbation.abs().mean().item()\n",
    "pgd_avg_perturbation = (pgd_adversarial - images_batch).abs().mean().item()\n",
    "print(f\"  FGSM平均扰动幅度: {fgsm_avg_perturbation:.6f}\")\n",
    "print(f\"  PGD平均扰动幅度:  {pgd_avg_perturbation:.6f}\")\n",
    "\n",
    "print(f\"\\n结论:\")\n",
    "if pgd_success_rate > success_rate:\n",
    "    print(\"  PGD攻击比FGSM攻击更有效\")\n",
    "elif pgd_success_rate < success_rate:\n",
    "    print(\"  FGSM攻击比PGD攻击更有效\")\n",
    "else:\n",
    "    print(\"  FGSM和PGD攻击效果相当\")\n",
    "\n",
    "if max(success_rate, pgd_success_rate) > 0.5:\n",
    "    print(\"  该模型对对抗攻击较为敏感\")\n",
    "else:\n",
    "    print(\"  该模型对对抗攻击具有一定的鲁棒性\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"实验完成!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089dc7e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:28:49.224078Z",
     "start_time": "2025-06-06T17:28:36.249379Z"
    }
   },
   "outputs": [],
   "source": [
    "# 对整个CUTE80数据集进行攻击和测试\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"开始对整个CUTE80数据集进行对抗攻击测试\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 重新加载所有图像文件，避免重复\n",
    "cute80_dir = Path(\"../CUTE80\")\n",
    "all_image_files = []\n",
    "for ext in ['*.jpg', '*.JPG', '*.png', '*.PNG']:\n",
    "    all_image_files.extend(list(cute80_dir.glob(ext)))\n",
    "\n",
    "# 去除重复文件（Windows文件系统中.jpg和.JPG可能指向同一文件）\n",
    "unique_files = {}\n",
    "for file_path in all_image_files:\n",
    "    # 使用文件的绝对路径作为唯一标识符\n",
    "    key = str(file_path.resolve()).lower()\n",
    "    if key not in unique_files:\n",
    "        unique_files[key] = file_path\n",
    "\n",
    "all_image_files = sorted(unique_files.values())\n",
    "print(f\"总共找到 {len(all_image_files)} 张图像\")\n",
    "\n",
    "# 批处理设置\n",
    "batch_size = 8  # 根据GPU内存调整\n",
    "total_images = len(all_image_files)\n",
    "num_batches = (total_images + batch_size - 1) // batch_size\n",
    "\n",
    "print(f\"将分 {num_batches} 个批次处理，每批 {batch_size} 张图像\")\n",
    "\n",
    "# 结果存储\n",
    "results = {\n",
    "    'image_name': [],\n",
    "    'original_text': [],\n",
    "    'fgsm_text': [],\n",
    "    'pgd_text': [],\n",
    "    'fgsm_success': [],\n",
    "    'pgd_success': [],\n",
    "    'fgsm_perturbation': [],\n",
    "    'pgd_perturbation': []\n",
    "}\n",
    "\n",
    "# 攻击参数\n",
    "epsilon = 0.1\n",
    "pgd_epsilon = 0.1\n",
    "pgd_alpha = 0.02\n",
    "pgd_iters = 10\n",
    "\n",
    "print(f\"\\n攻击参数:\")\n",
    "print(f\"  FGSM epsilon: {epsilon}\")\n",
    "print(f\"  PGD epsilon: {pgd_epsilon}, alpha: {pgd_alpha}, iterations: {pgd_iters}\")\n",
    "print(f\"  批处理大小: {batch_size}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 分批处理图像\n",
    "for batch_idx in tqdm(range(num_batches), desc=\"处理批次\"):\n",
    "    # 计算当前批次的图像范围\n",
    "    start_idx = batch_idx * batch_size\n",
    "    end_idx = min(start_idx + batch_size, total_images)\n",
    "    current_batch_files = all_image_files[start_idx:end_idx]\n",
    "    \n",
    "    try:\n",
    "        # 为当前批次加载图像\n",
    "        batch_images = []\n",
    "        batch_names = []\n",
    "        \n",
    "        for img_path in current_batch_files:\n",
    "            # 加载图像\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img_tensor = transform(img)\n",
    "            batch_images.append(img_tensor)\n",
    "            batch_names.append(img_path.stem)\n",
    "        \n",
    "        # 创建批次张量\n",
    "        batch_tensor = torch.stack(batch_images).to(device)\n",
    "        \n",
    "        # 获取原始识别结果\n",
    "        original_batch_texts = predict_text(model, batch_tensor)\n",
    "        \n",
    "        # 执行FGSM攻击\n",
    "        fgsm_adversarial_batch = attacker.fgsm_attack(batch_tensor, epsilon=epsilon)\n",
    "        fgsm_batch_texts = predict_text(model, fgsm_adversarial_batch)\n",
    "        \n",
    "        # 执行PGD攻击\n",
    "        pgd_adversarial_batch = attacker.pgd_attack(batch_tensor, \n",
    "                                                   epsilon=pgd_epsilon, \n",
    "                                                   alpha=pgd_alpha, \n",
    "                                                   iters=pgd_iters)\n",
    "        pgd_batch_texts = predict_text(model, pgd_adversarial_batch)\n",
    "        \n",
    "        # 计算扰动\n",
    "        fgsm_perturbations = (fgsm_adversarial_batch - batch_tensor).abs().mean(dim=[1,2,3])\n",
    "        pgd_perturbations = (pgd_adversarial_batch - batch_tensor).abs().mean(dim=[1,2,3])\n",
    "        \n",
    "        # 保存结果\n",
    "        for i in range(len(current_batch_files)):\n",
    "            results['image_name'].append(batch_names[i])\n",
    "            results['original_text'].append(original_batch_texts[i])\n",
    "            results['fgsm_text'].append(fgsm_batch_texts[i])\n",
    "            results['pgd_text'].append(pgd_batch_texts[i])\n",
    "            results['fgsm_success'].append(original_batch_texts[i] != fgsm_batch_texts[i])\n",
    "            results['pgd_success'].append(original_batch_texts[i] != pgd_batch_texts[i])\n",
    "            results['fgsm_perturbation'].append(fgsm_perturbations[i].item())\n",
    "            results['pgd_perturbation'].append(pgd_perturbations[i].item())\n",
    "        \n",
    "        # 显示进度信息\n",
    "        if (batch_idx + 1) % 10 == 0 or batch_idx == 0:\n",
    "            current_progress = (batch_idx + 1) / num_batches * 100\n",
    "            current_fgsm_success = sum(results['fgsm_success'])\n",
    "            current_pgd_success = sum(results['pgd_success']) \n",
    "            current_total = len(results['image_name'])\n",
    "            print(f\"\\n进度 {current_progress:.1f}% - 已处理 {current_total} 张图像\")\n",
    "            print(f\"当前FGSM成功率: {current_fgsm_success/current_total:.1%}\")\n",
    "            print(f\"当前PGD成功率: {current_pgd_success/current_total:.1%}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n批次 {batch_idx + 1} 处理失败: {e}\")\n",
    "        # 为失败的图像添加默认值\n",
    "        for img_path in current_batch_files:\n",
    "            results['image_name'].append(img_path.stem)\n",
    "            results['original_text'].append(\"ERROR\")\n",
    "            results['fgsm_text'].append(\"ERROR\")\n",
    "            results['pgd_text'].append(\"ERROR\")\n",
    "            results['fgsm_success'].append(False)\n",
    "            results['pgd_success'].append(False)\n",
    "            results['fgsm_perturbation'].append(0.0)\n",
    "            results['pgd_perturbation'].append(0.0)\n",
    "        continue\n",
    "\n",
    "end_time = time.time()\n",
    "processing_time = end_time - start_time\n",
    "\n",
    "print(f\"\\n处理完成! 总耗时: {processing_time:.2f} 秒\")\n",
    "print(f\"平均每张图像处理时间: {processing_time/total_images:.3f} 秒\")\n",
    "\n",
    "# 创建结果DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Complete Dataset Attack Results Statistics\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8526d035",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:28:49.611484Z",
     "start_time": "2025-06-06T17:28:49.225024Z"
    }
   },
   "outputs": [],
   "source": [
    "# 分析和可视化整个数据集的攻击结果\n",
    "\n",
    "# 基本统计\n",
    "total_samples = len(df_results)\n",
    "fgsm_success_count = df_results['fgsm_success'].sum()\n",
    "pgd_success_count = df_results['pgd_success'].sum()\n",
    "fgsm_success_rate = fgsm_success_count / total_samples\n",
    "pgd_success_rate = pgd_success_count / total_samples\n",
    "\n",
    "print(f\"数据集规模: {total_samples} 张图像\")\n",
    "print(f\"FGSM攻击成功: {fgsm_success_count} / {total_samples} = {fgsm_success_rate:.1%}\")\n",
    "print(f\"PGD攻击成功:  {pgd_success_count} / {total_samples} = {pgd_success_rate:.1%}\")\n",
    "\n",
    "# 扰动分析\n",
    "avg_fgsm_perturbation = df_results['fgsm_perturbation'].mean()\n",
    "avg_pgd_perturbation = df_results['pgd_perturbation'].mean()\n",
    "std_fgsm_perturbation = df_results['fgsm_perturbation'].std()\n",
    "std_pgd_perturbation = df_results['pgd_perturbation'].std()\n",
    "\n",
    "print(f\"\\n扰动统计:\")\n",
    "print(f\"FGSM平均扰动: {avg_fgsm_perturbation:.6f} ± {std_fgsm_perturbation:.6f}\")\n",
    "print(f\"PGD平均扰动:  {avg_pgd_perturbation:.6f} ± {std_pgd_perturbation:.6f}\")\n",
    "\n",
    "# 成功案例分析\n",
    "successful_fgsm = df_results[df_results['fgsm_success'] == True]\n",
    "successful_pgd = df_results[df_results['pgd_success'] == True]\n",
    "both_successful = df_results[(df_results['fgsm_success'] == True) & \n",
    "                            (df_results['pgd_success'] == True)]\n",
    "\n",
    "print(f\"\\n攻击成功模式分析:\")\n",
    "print(f\"仅FGSM成功: {len(successful_fgsm) - len(both_successful)} 个案例\")\n",
    "print(f\"仅PGD成功:  {len(successful_pgd) - len(both_successful)} 个案例\")\n",
    "print(f\"两种攻击都成功: {len(both_successful)} 个案例\")\n",
    "print(f\"两种攻击都失败: {total_samples - len(successful_fgsm.index.union(successful_pgd.index))} 个案例\")\n",
    "\n",
    "# 保存详细结果到CSV文件\n",
    "results_file = 'adversarial_attack_results_full_dataset.csv'\n",
    "df_results.to_csv(results_file, index=False, encoding='utf-8')\n",
    "print(f\"\\n详细结果已保存到: {results_file}\")\n",
    "\n",
    "# 可视化结果\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 创建综合分析图表\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle(f'CUTE80 Dataset Adversarial Attack Complete Analysis ({total_samples} Images)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Attack Success Rate Comparison\n",
    "axes[0, 0].bar(['FGSM', 'PGD'], [fgsm_success_rate*100, pgd_success_rate*100], \n",
    "               color=['lightcoral', 'lightblue'], alpha=0.7)\n",
    "axes[0, 0].set_ylabel('Success Rate (%)')\n",
    "axes[0, 0].set_title('Attack Success Rate Comparison')\n",
    "axes[0, 0].set_ylim(0, 100)\n",
    "for i, v in enumerate([fgsm_success_rate*100, pgd_success_rate*100]):\n",
    "    axes[0, 0].text(i, v + 1, f'{v:.1f}%', ha='center', fontweight='bold')\n",
    "\n",
    "# 2. Perturbation Magnitude Distribution\n",
    "axes[0, 1].hist(df_results['fgsm_perturbation'], bins=30, alpha=0.6, label='FGSM', color='lightcoral')\n",
    "axes[0, 1].hist(df_results['pgd_perturbation'], bins=30, alpha=0.6, label='PGD', color='lightblue')\n",
    "axes[0, 1].set_xlabel('Perturbation Magnitude')\n",
    "axes[0, 1].set_ylabel('Number of Images')\n",
    "axes[0, 1].set_title('Perturbation Magnitude Distribution')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. FGSM Attack Success vs Perturbation Relationship\n",
    "fgsm_successful_pert = df_results[df_results['fgsm_success']]['fgsm_perturbation']\n",
    "fgsm_failed_pert = df_results[~df_results['fgsm_success']]['fgsm_perturbation']\n",
    "axes[0, 2].boxplot([fgsm_successful_pert, fgsm_failed_pert], \n",
    "                   labels=['FGSM Success', 'FGSM Failed'])\n",
    "axes[0, 2].set_ylabel('Perturbation Magnitude')\n",
    "axes[0, 2].set_title('FGSM Attack Success vs Perturbation')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Attack Pattern Distribution Pie Chart\n",
    "attack_patterns = ['Both Success', 'FGSM Only', 'PGD Only', 'Both Failed']\n",
    "pattern_counts = [\n",
    "    len(both_successful),\n",
    "    len(successful_fgsm) - len(both_successful),\n",
    "    len(successful_pgd) - len(both_successful),\n",
    "    total_samples - len(successful_fgsm.index.union(successful_pgd.index))\n",
    "]\n",
    "colors = ['red', 'orange', 'yellow', 'lightgray']\n",
    "axes[1, 0].pie(pattern_counts, labels=attack_patterns, autopct='%1.1f%%', colors=colors)\n",
    "axes[1, 0].set_title('Attack Pattern Distribution')\n",
    "\n",
    "# 5. PGD Attack Success vs Perturbation Relationship\n",
    "pgd_successful_pert = df_results[df_results['pgd_success']]['pgd_perturbation']\n",
    "pgd_failed_pert = df_results[~df_results['pgd_success']]['pgd_perturbation']\n",
    "axes[1, 1].boxplot([pgd_successful_pert, pgd_failed_pert], \n",
    "                   labels=['PGD Success', 'PGD Failed'])\n",
    "axes[1, 1].set_ylabel('Perturbation Magnitude')\n",
    "axes[1, 1].set_title('PGD Attack Success vs Perturbation')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 6. FGSM vs PGD Perturbation Magnitude Scatter Plot\n",
    "axes[1, 2].scatter(df_results['fgsm_perturbation'], df_results['pgd_perturbation'], \n",
    "                   alpha=0.6, s=20)\n",
    "axes[1, 2].plot([0, max(df_results['fgsm_perturbation'].max(), df_results['pgd_perturbation'].max())], \n",
    "                [0, max(df_results['fgsm_perturbation'].max(), df_results['pgd_perturbation'].max())], \n",
    "                'r--', alpha=0.5)\n",
    "axes[1, 2].set_xlabel('FGSM Perturbation Magnitude')\n",
    "axes[1, 2].set_ylabel('PGD Perturbation Magnitude')\n",
    "axes[1, 2].set_title('FGSM vs PGD Perturbation Comparison')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"数据集攻击分析完成!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parseq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
